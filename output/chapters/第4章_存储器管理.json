[
  {
    "一级标题": "第4章_存储器管理",
    "二级内容": [
      {
        "二级标题": "4.1_存储器的层次结构",
        "三级内容": [
          {
            "三级标题": "4.1.1 多层结构的存储器系统",
            "正文": "1.存储器的多层结构 对于通用计算机而言，存储层次至少应具有三级：最高层为CPU寄存器，中间为主存， 最底层是辅存。在较高档的计算机中，还可以根据具体的功能细分为寄存器、高速缓存、 主存储器、磁盘缓存、固定磁盘、可移动 存储介质等6层。如图4-1所示。在存储 CPU寄存器{ 寄存器 层次中，层次越高（越靠近CPU)，存储介 高速缓存 质的访问速度越快，价格也越高，相对所 主存 主存储器 配置的存储容量也越小。其中，寄存器、 磁盘缓存 高速缓存、主存储器和磁盘缓存均属于操 固定磁盘 辅存 作系统存储管理的管辖范畴，掉电后它们 可移动存储介质 中存储的信息不再存在。而低层的固定磁 盘和可移动存储介质则属于设备管理的管 图4-1计算机系统存储层次示意 辖范畴，它们存储的信息将被长期保存。 120  第四章存储器管理\n\n2.可执行存储器 在计算机系统的存储层次中，寄存器和主存储器又被称为可执行存储器。对于存放于 其中的信息，与存放于辅存中的信息相比较而言，计算机所采用的访问机制是不同的，所 需耗费的时间也是不同的。进程可以在很少的时钟周期内使用一条load或store指令对可 执行存储器进行访问。但对辅存的访问则需要通过IO设备实现，因此，在访问中将涉及 到中断、设备驱动程序以及物理设备的运行，所需耗费的时间远远高于访问可执行存储器 的时间，一般相差3个数量级甚至更多。 对于不同层次的存储介质，由操作系统进行统一管理。操作系统的存储管理负责对可 执行存储器的分配、回收，以及提供在存储层次间数据移动的管理机制，例如主存与磁盘 缓存、高速缓存与主存间的数据移动等。而设备和文件管理则根据用户的需求，提供对辅 存的管理机制。本章主要讨论有关存储管理部分的内容，对于辅存部分，则放在以后的章 节中进行介绍。"
          },
          {
            "三级标题": "4.1.2 主存储器与寄存器",
            "正文": "1.主存储器 和数据，也称可执行存储器。通常，处理机都是从主存储器中取得指令和数据的，并将其 所取得的指令放入指令寄存器中，而将其所读取的数据装入到数据寄存器中；或者反之， 将寄存器中的数据存入到主存储器。早期的内存是由磁芯做成的，其容量一般为数十KB 到数百KB。随着VLSI的发展，现在的内存已由VLSI构成，其容量，即使是微机系统， MB。CPU与外围设备交换的信息一般也依托于主存储器的地址空间。由于主存储器访问 速度远低于CPU执行指令的速度，为缓和这一矛盾，在计算机系统中引I入了寄存器和高速 缓存。\n\n2.寄存器 寄存器具有与处理机相同的速度，故对寄存器的访问速度最快，完全能与CPU协调工 作，但价格却十分昂贵，因此容量不可能做得很大。在早期计算机中，寄存器的数目仅为 几个，主要用于存放处理机运行时的数据，以加速存储器的访问速度，如使用寄存器存放 操作数，或用作地址寄存器加快地址转换速度等。随着VLSI的发展，寄存器的成本也在 迅速降低，在当前的微机系统和大中型机中，寄存器的数目都已增加到数十个到数百个， 而寄存器的字长一般是32位或64位；而在小型的嵌入式计算机中，寄存器的数目仍只有 几个到十几个，而且寄存器的字长通常只有8位。"
          },
          {
            "三级标题": "4.1.3 高速缓存和磁盘缓存",
            "正文": "1.高速缓存 高速缓存是现代计算机结构中的一个重要部件，它是介于寄存器和存储器之间的存储 器，主要用于备份主存中较常用的数据，以减少处理机对主存储器的访问次数，这样可大 121  计算机操作系统 幅度地提高程序执行速度。高速缓存容量远大于寄存器，而比内存约小两到三个数量级左 右，从几十KB到几MB，访问速度快于主存储器。在计算机系统中，为了缓和内存与处 理机速度之间的矛盾，许多地方都设置了高速缓存。在以后各章中将会经常遇见各种高速 缓存的，届时再对它们进行详细的介绍。 将一些常用数据放在高速缓存中是否有效，这将涉及到程序执行的局部性原理（前已提 及：程序在执行时将呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个 部分。关于局部性原理问题，我们将在第五章中做进一步的介绍)。通常，进程的程序和数 据存放在主存储器中，每当要访问时，才被临时复制到一个速度较快的高速缓存中。这样， 当CPU访问一组特定信息时，须首先检查它是否在高速缓存中，如果已存在，便可直接从 中取出使用，以避免访问主存，否则，就须从主存中读出信息。如大多数计算机都有指令 高速缓存，用来暂存下一条将执行的指令，如果没有指令高速缓存，CPU将会空等若干个 周期，直到下一条指令从主存中取出。由于高速缓存的速度越高价格也越贵，故在有的计 算机系统中设置了两级或多级高速缓存。紧靠内存的一级高速缓存的速度最高，而容量最 小，二级高速缓存的容量稍大，速度也稍低。\n\n2.磁盘缓存 由于目前磁盘的I/O速度远低于对主存的访问速度，为了缓和两者之间在速度上的不 访问磁盘的次数。但磁盘缓存与高速缓存不同，它本身并不是一种实际存在的存储器，而 是利用主存中的部分存储空间暂时存放从磁盘中读出（或写入)的信息。主存也可以看作是 辅存的高速缓存，因为，辅存中的数据必须复制到主存方能使用，反之，数据也必须先存 在主存中，才能输出到辅存。 一个文件的数据可能先后出现在不同层次的存储器中，例如，一个文件的数据通常被 存储在辅存中(如硬盘)，当其需要运行或被访问时，就必须调入主存，也可以暂时存放在 主存的磁盘高速缓存中。大容量的辅存常常使用磁盘，磁盘数据经常备份到磁带或可移动 磁盘组上，以防止硬盘故障时丢失数据。有些系统自动地把老文件数据从辅存转储到海量 存储器中，如磁带上，这样做还能降低存储价格。 1/4.2程序的装入和链接 用户程序要在系统中运行，必须先将它装入内存，然后再将其转变为一个可以执行的 程序，通常都要经过以下几个步骤：\n\n(1）编译，由编译程序(Compiler)对用户源程序进行编译，形成若干个目标模块(Object Module);\n\n(2）链接，由链接程序(Linker)将编译后形成的一组目标模块以及它们所需要的库函数 链接在一起，形成一个完整的装入模块(Load Module);\n\n(3）装入，由装入程序(Loader)将装入模块装入内存。 图4-2示出了这样的三步过程。本节将扼要阐述程序(含数据)的链接和装入过程。 122"
          }
        ]
      },
      {
        "二级标题": "4.2_程序的装入和链接",
        "三级内容": [
          {
            "三级标题": "4.2.1 程序的装入 为了阐述上的方便，我们先介绍一个无需进行链接的单个目标模块的装入过程。该目 标模块也就是装入模块。在将一个装入模块装入内存时，可以有如下三种装入方式：",
            "正文": "1.绝对装入方式（AbsoluteLoadingMode） 当计算机系统很小，且仅能运行单道程序时，完全有可能知道程序将驻留在内存的什 么位置。此时可以采用绝对装入方式。用户程序经编译后，将产生绝对地址（即物理地址） 的目标代码。例如，事先已知用户程序（进程）驻留在从R处开始的位置，则编译程序所产 生的目标模块(即装入模块)，便可从R处开始向上扩展。绝对装入程序便可按照装入模块 中的地址，将程序和数据装入内存。装入模块被装入内存后，由于程序中的相对地址（即逻 辑地址）与实际内存地址完全相同，故不需对程序和数据的地址进行修改。 程序中所使用的绝对地址既可在编译或汇编时给出，也可由程序员直接赋予。但由程 序员直接给出绝对地址时，不仅要求程序员熟悉内存的使用情况，而且一旦程序或数据被 修改后，可能要改变程序中的所有地址。因此，通常是宁可在程序中采用符号地址，然后 在编译或汇编时，再将这些符号地址转换为绝对地址。\n\n2.可重定位装入方式（RelocationLoadingMode） 绝对装入方式只能将目标模块装入到内存中事先指定的位置，这只适用于单道程序环 何处。因此，对于用户程序编译所形成的若干个目标模块，它们的起始地址通常都是从0 开始的，程序中的其它地址也都是相对于起始地址计算的。此时，不可能再用绝对装入方 式，而应采用可重定位装入方式，它可以根据内存的具体情况将装入模块装入到内存的适 当位置。 值得注意的是，在采用可重定位装入程序将装入模块装入内存后，会使装入模块中的 所有逻辑地址与实际装入内存后的物理地址不同，图4-3示出了这一情况。例如，在用户 程序的1000号单元处有一条指令LOAD1，2500，该指令的功能是将2500单元中的整数 365取至寄存器1。但若将该用户程序装入到内存的10000～15000号单元而不进行地址变 换，则在执行11000号单元中的指令时，它将仍从2500号单元中把数据取至寄存器1，而 123  计算机操作系统 导致数据错误。由图4-3可见，正确的方法应该是，将取数指令中的地址2500修改成12500， 即把指令中的逻辑地址2500与本程序在内存中的起始地址10000相加，才得到正确的物理 地址12500。除了数据地址应修改外，指令地址也须做同样的修改，即将指令的逻辑地址 1000与起始地址10000相加，得到绝对地址11000。通常，把在装入时对目标程序中指令 和数据地址的修改过程称为重定位。又因为地址变换通常是在进程装入时一次完成的，以 后不再改变，故称为静态重定位。 0 10000 1000 LOAD12500 11000 LOAD12500 2500 365 12500 365 5000 15000 作业地址空间 内存空间 图4-3作业装入内存时的情况\n\n3.动态运行时的装入方式（DynamicRun-timeLoading） 可重定位装入方式可将装入模块装入到内存中任何允许的位置，故可用于多道程序环 境。但该方式并不充许程序运行时在内存中移动位置。因为，程序在内存中的移动，意味 着它的物理位置发生了变化，这时必须对程序和数据的地址（绝对地址）进行修改后方能运 行。然而，实际情况是，在运行过程中它在内存中的位置可能经常要改变，例如，在具有 对换功能的系统中，一个进程可能被多次换出，又多次被换入，每次换入后的位置通常是 不同的。在这种情况下，就应采用动态运行时装入的方式。 动态运行时的装入程序在把装入模块装入内存后，并不立即把装入模块中的逻辑地址 转换为物理地址，而是把这种地址转换推迟到程序真正要执行时才进行。因此，装入内存 后的所有地址都仍是逻辑地址。为使地址转换不影响指令的执行速度，这种方式需要一个 重定位寄存器的支持，我们将在本章4.3节中做详细介绍。"
          },
          {
            "三级标题": "4.2.2 程序的链接 源程序经过编译后，可得到一组目标模块。链接程序的功能是将这组目标模块以及它 们所需要的库函数装配成一个完整的装入模块。在对目标模块进行链接时，根据进行链接 的时间不同，可把链接分成如下三种。",
            "正文": "1.静态链接（StaticLinking）方式 在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块， 以后不再拆开。我们把这种事先进行链接的方式称为静态链接方式。我们通过一个例子来 说明在实现静态链接时应解决的一些问题。在图4-4(a)中示出了经过编译后所得到的三个 目标模块A、B、C，它们的长度分别为L、M和N。在模块A中有一条语句CALLB，用 124  第四章存储器管理 于调用模块B。在模块B中有一条语句CALLC，用于调用模块C。B和C都属于外部调 用符号，在将这几个目标模块装配成一个装入模块时，须解决以下两个问题：\n\n（1）对相对地址进行修改。在由编译程序所产生的所有目标模块中，使用的都是相对 地址，其起始地址都为0，每个模块中的地址都是相对于起始地址计算的。在链接成一个 装入模块后，原模块B和C在装入模块的起始地址不再是0，而分别是L和L+M，所以 有相对地址都加上L+M。\n\n（2）变换外部调用符号。将每个模块中所用的外部调用符号也都变换为相对地址，如 链接所形成的一个完整的装入模块，又称为可执行文件。通常都不再把它拆开，要运行时 可直接将它装入内存。把这种事先进行链接而以后不再拆开的链接方式称为静态链接方式。 模块A 模块A CALL B; JSR“L\" L-1 Return; L- Return: 模块B 模块B CALL C; JSR“L+M\" M-1 Return; L+M-1 Return; L+M 模块C 模块C ） L+M+N-1 Return; N-1 Return; (a)目标模块 (b)装入模块 图4-4程序链接示意图\n\n2.装入时动态链接（Load-timeDynamicLinking） 接的链接方式。即在装入一个目标模块时，若发生一个外部模块调用事件，将引起装入程 序去找出相应的外部目标模块，并将它装入内存，还要按照图4-4所示的方式修改目标模 块中的相对地址。装入时动态链接方式有以下优点：\n\n(1）便于修改和更新。对于经静态链接装配在一起的装入模块，如果要修改或更新其 中的某个目标模块，则要求重新打开装入模块。这不仅是低效的，而且有时是不可能的。 若采用动态链接方式，由于各目标模块是分开存放的，所以要修改或更新各目标模块是件 非常容易的事。\n\n(2）便于实现对目标模块的共享。在采用静态链接方式时，每个应用模块都必须含有 其目标模块的拷贝，无法实现对目标模块的共享。但采用装入时动态链接方式时，OS就很 容易将一个目标模块链接到几个应用模块上，实现多个应用程序对该模块的共享。\n\n3.运行时动态链接（Run-timeDynamicLinking） 在许多情况下，应用程序在运行时，每次要运行的模块可能是不相同的。但由于事先 无法知道本次要运行哪些模块，故只能是将所有可能要运行到的模块全部都装入内存，并 在装入时全部链接在一起。显然这是低效的，因为往往会有部分目标模块根本就不运行。 125  计算机操作系统 比较典型的例子是作为错误处理用的目标模块，如果程序在整个运行过程中都不出现错误， 则显然就不会用到该模块。 近几年流行起来的运行时动态链接方式，是对上述装入时链接方式的一种改进。这种 链接方式是，将对某些模块的链接推迟到程序执行时才进行。亦即，在执行过程中，当发 现一个被调用模块尚未装入内存时，立即由OS去找到该模块，并将之装入内存，将其链 接到调用者模块上。凡在执行过程中未被用到的目标模块，都不会被调入内存和被链接到 装入模块上，这样不仅能加快程序的装入过程，而且可节省大量的内存空间。\n\n14.3连续分配存储管理方式 为了能将用户程序装入内存，必须为它分配一定大小的内存空间。连续分配方式是最 早出现的一种存储器分配方式，曾被广泛应用于上世纪60～80年代的OS中，该分配方式 为一个用户程序分配一个连续的内存空间，即程序中代码或数据的逻辑地址相邻，体现在 内存空间分配时物理地址的相邻。连续分配方式可分为四类：单一连续分配、固定分区分 配、动态分区分配以及动态可重定位分区分配算法四种方式。"
          },
          {
            "三级标题": "4.3.1 单一连续分配 一一← 在单道程序环境下，当时的存储器管理方式是把内存分为系统区和用户区两部分，系 统区仅提供给OS使用，它通常是放在内存的低址部分。而在用户区内存中，仅装有一道 用户程序，即整个内存的用户空间由该程序独占。这样的存储器分配方式被称为单一连续 分配方式。 虽然在早期的单用户、单任务操作系统中，有不少都配置了存储器保护机构，用于防 正用户程序对操作系统的破坏，但在20世纪80年代所产生的几种常见的单用户操作系统 中，如CP/M、MS-DOS及RT11等，并未采取存储器保护措施。这是因为，一方面可以节 省硬件，另一方面在单用户环境下，机器由一用户独占，不可能存在其他用户干扰的问题， 因此这是可行的。即使出现破坏行为，也仅仅会是用户程序自己破坏操作系统，其后果并不",
            "正文": ""
          },
          {
            "三级标题": "4.3.2 固定分区分配 一一→ 20世纪60年代出现的多道程序系统，如IBM360的MFT操作系统，为了能在内存中 装入多道程序，且使这些程序之间又不会发生相互干扰，于是将整个用户空间划分为若干 个固定大小的区域，在每个分区中只装入一道作业，这样就形成了最早的、也是最简单的 一种可运行多道程序的分区式存储管理方式。如果在内存中有四个用户分区，便允许四个 程序并发运行。当有一空闲分区时，便可以再从外存的后备作业队列中选择一个适当大 小的作业，装入该分区。当该作业结束时，又可再从后备作业队列中找出另一作业调入 该分区。",
            "正文": "1.划分分区的方法 可用下述两种方法将内存的用户空间划分为若干个固定大小的分区： 126"
          }
        ]
      },
      {
        "二级标题": "4.3_连续分配存储管理方式",
        "三级内容": [
          {
            "三级标题": "4.3.2 固定分区分配 一一→ 20世纪60年代出现的多道程序系统，如IBM360的MFT操作系统，为了能在内存中 装入多道程序，且使这些程序之间又不会发生相互干扰，于是将整个用户空间划分为若干 个固定大小的区域，在每个分区中只装入一道作业，这样就形成了最早的、也是最简单的 一种可运行多道程序的分区式存储管理方式。如果在内存中有四个用户分区，便允许四个 程序并发运行。当有一空闲分区时，便可以再从外存的后备作业队列中选择一个适当大 小的作业，装入该分区。当该作业结束时，又可再从后备作业队列中找出另一作业调入 该分区。",
            "正文": "1.划分分区的方法 可用下述两种方法将内存的用户空间划分为若干个固定大小的分区： 126  第四章存储器管理\n\n(1）分区大小相等(指所有的内存分区大小相等)。其缺点是缺乏灵活性，即当程序太小 时，会造成内存空间的浪费。当程序太大时，一个分区又不足以装入该程序，致使该程序 无法运行。尽管如此，对于利用一台计算机同时控制多个相同对象的场合，因为这些对象 所需的内存空间大小往往相同，这种划分方式比较方便和实用，所以被广泛采用。例如， 炉温群控系统就是利用一台计算机去控制多台相同的冶炼炉。\n\n(2）分区大小不等。为了增加存储器分配的灵活性，应将存储器分区划分为若干个大 小不等的分区。最好能对常在该系统中运行的作业大小进行调查，根据用户的需要来划分。 通常，可把内存区划分成含有多个较小的分区、适量的中等分区及少量的大分区，这样， 便可根据程序的大小，为之分配适当的分区。\n\n2.内存分配 为了便于内存分配，通常将分区按其大小进行排队，并为之建立一张分区使用表，其 中各表项包括每个分区的起始地址、大小及状态（是否已分配)，如图4-5所示。当有一用户 的、尚未分配的分区，将之分配给该程序，然后将该表项中的状态置为“已分配”。若未找 到大小足够的分区，则拒绝为该用户程序分配内存。 空间 操作系统 24KB 作业A 32KB 作业B 64KB 作业C 分区号 大小(KB) 起址(K) 状态 128KB 1 12 20 已分配 2 32 32 已分配 ... 3 64 64 未分配 256KB 4 128 128 已分配 (a)分区说明表 (b)存储空间分配情况 图4-5固定分区使用表 固定分区分配是最早出现的、可用于多道程序系统中的存储管理方式，由于每个分区 的大小固定，必然会造成存储空间的浪费，因而现在已很少将它用于通用的OS中。但在 某些用于控制多个相同对象的控制系统中，由于每个对象的控制程序大小相同，是事先已 编好的，其所需的数据也是一定的，故仍采用固定分区式存储管理方式。"
          },
          {
            "三级标题": "4.3.3 动态分区分配 动态分区分配又称为可变分区分配，它是根据进程的实际需要，动态地为之分配内存 空间。在实现动态分区分配时，将涉及到分区分配中所用的数据结构、分区分配算法和分 区的分配与回收操作这样三方面的问题。 127  计算机操作系统",
            "正文": "1.动态分区分配中的数据结构 为了实现动态分区分配，系统中必须配置相应的数据结构，用以描述空闲分区和已分 配分区的情况，为分配提供依据。常用的数据结构有以下两种形式：①空闲分区表，在系 统中设置一张空闲分区表，用于记录每个空闲分区的情况。每个空闲分区占一个表目，表 目中包括分区号、分区大小和分区始址等数据项，如图4-6所示。②空闲分区链。为了实 现对空闲分区的分配和链接，在每个分区的起始部分设置一些用于控制分区分配的信息， 以及用于链接各分区所用的前向指针，在分区尾部则设置一后向指针。通过前、后向链接 指针，可将所有的空闲分区链接成一个双向链，如图4-7所示。为了检索方便，在分区尾 部重复设置状态位和分区大小表目。当分区被分配出去以后，把状态位由“0”改为“1”， 此时，前、后向指针已无意义。 前 后 分区号 分区大小（KB) 分区始址(K) 状态 向 向 指 50 85 空闲 1 针 2 32 155 空闲 N个字节可用 N+2 N+2 3 70 275 空闲 4 60 532 空闲 0 0 5 ... ... .. 图4-6空闲分区表 图4-7空闲链结构\n\n2.动态分区分配算法 为把一个新作业装入内存，须按照一定的分配算法，从空闲分区表或空闲分区链中选 出一分区分配给该作业。由于内存分配算法对系统性能有很大的影响，故人们对它进行了 较为广泛而深入的研究，于是产生了许多动态分区分配算法。我们将在下一小节先介绍传 统的四种分配算法，它们都属于顺序式搜索算法。再下一节，我们将介绍三种较新的索引 式搜索算法。\n\n3.分区分配操作 在动态分区存储管理方式中，主要的操作是分配内存和回收内存。 1）分配内存 系统应利用某种分配算法，从空闲分区链(表)中找到所需大小的分区。设请求的分区 大小为u.size，表中每个空闲分区的大小可表示为m.size。若m.size-u.size≤size(size是事先 规定的不再切割的剩余分区的大小)，说明多余部分太小，可不再切割，将整个分区分配给 请求者。否则(即多余部分超过size)，便从该分区中按请求的大小划分出一块内存空间分配 出去，余下的部分仍留在空闲分区链(表)中。然后，将分配区的首址返回给调用者。图4-8 示出了分配流程。 128  第四章存储器管理 从头开始查表 检索完否？ 返回 N N m.size>u.size? 继续检索下一个表项 人 Y m.size-u.size≤size？ N 从该分区中划出 将该分区从链中移出 u.size大小的分区 将该分区分配给请求者， 修改有关数据结构 返回 图4-8内存分配流程 2）回收内存 当进程运行完毕释放内存时，系统根据回收区的首址，从空闲区链(表)中找到相应的 插入点，此时可能出现以下四种情况之一：\n\n(1）回收区与插入点的前一个空闲分区F相邻接，见图4-9(a)。此时应将回收区与插 入点的前一分区合并，不必为回收分区分配新表项，而只需修改其前一分区F的大小。\n\n(2）回收分区与插入点的后一空闲分区F2相邻接，见图4-9(b)。此时也可将两分区合 并，形成新的空闲分区，但用回收区的首址作为新空闲区的首址，大小为两者之和。\n\n(3）回收区同时与插入点的前、后两个分区邻接，见图4-9(c)。此时将三个分区合并， 使用F的表项和F的首址，取消F2的表项，大小为三者之和。 ... .·. **. F F 回收区 回收区 回收区 F2 F2 .. ... (a) (b) (c) 图4-9内存回收时的情况 129  计算机操作系统\n\n(4）回收区既不与F邻接，又不与F2邻接。这时应为回收区单独建立一个新表项，填 写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。图4-10示出了内存回 收时的流程。 回收区 m.free 顺序次检索可用资源表 直至找到某表目的 m.addr>aa 或m.size=0 否 是 不是第一个表目且 与前一个可用区相邻？ 把所释放的可用区 是 与后一可用分区相 否 与前一分区合并 邻且不为空表目？ 所释放的可用区 与后一可用区 的size=0? 相邻？ 所释放的可用区 与后一可用区合并 是 是 将该表目以上的所有表目 上移一格，并插入 与后一可用区合并 新释放的可用区表目 将该表目以上的所有表目 返回 下移一格 图4-10内存回收流程"
          },
          {
            "三级标题": "4.3.4 基于顺序搜索的动态分区分配算法 为了实现动态分区分配，通常是将系统中的空闲分区链接成一个链。所谓顺序搜索， 是指依次搜索空闲分区链上的空闲分区，去寻找一个其大小能满足要求的分区。基于顺序 搜索的动态分区分配算法有如下四种：首次适应算法、循环首次适应算法、最佳适应算法 和最坏适应算法，下面分别进行介绍。",
            "正文": "1.首次适应（firstfit，FF)算法 我们以空闲分区链为例来说明采用FF算法时的分配情况。FF算法要求空闲分区链以 地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要 求的空闲分区为止。然后再按照作业的大小，从该分区中划出一块内存空间，分配给请求 者，余下的空闲分区仍留在空闲链中。若从链首直至链尾都不能找到一个能满足要求的分 区，则表明系统中已没有足够大的内存分配给该进程，内存分配失败，返回。 该算法倾向于优先利用内存中低址部分的空闲分区，从而保留了高址部分的大空闲区。 这为以后到达的大作业分配大的内存空间创造了条件。其缺点是低址部分不断被划分，会 留下许多难以利用的、很小的空闲分区，称为碎片。而每次查找又都是从低址部分开始的， 130  第四章存储器管理人 这无疑又会增加查找可用空闲分区时的开销。\n\n2.循环首次适应(next fit，NF)算法 为避免低址部分留下许多很小的空闲分区，以及减少查找可用空闲分区的开销，循环 首次适应算法在为进程分配内存空间时，不再是每次都从链首开始查找，而是从上次找到 的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区，从中划出 一块与请求大小相等的内存空间分配给作业。为实现该算法，应设置一起始查寻指针，用 于指示下一次起始查寻的空闲分区，并采用循环查找方式，即如果最后一个（链尾）空闲分 区的大小仍不能满足要求，则应返回到第一个空闲分区，比较其大小是否满足要求。找到 后，应调整起始查寻指针。该算法能使内存中的空闲分区分布得更均匀，从而减少了查找 空闲分区时的开销，但这样会缺乏大的空闲分区。\n\n3.最佳适应（bestfit，BF)算法 所谓“最佳”是指，每次为作业分配内存时，总是把能满足要求、又是最小的空闲分 区分配给作业，避免“大材小用”。为了加速寻找，该算法要求将所有的空闲分区按其 容量以从小到大的顺序形成一空闲分区链。这样，第一次找到的能满足要求的空闲区必 然是最佳的。孤立地看，最佳适应算法似乎是最佳的，然而在宏观上却不一定。因为每 次分配后所切割下来的剩余部分总是最小的，这样，在存储器中会留下许多难以利用的 碎片。\n\n4.最坏适应（worstfit，WF)算法 由于最坏适应分配算法选择空闲分区的策略正好与最佳适应算法相反：它在扫描整个 空闲分区表或链表时，总是挑选一个最大的空闲区，从中分割一部分存储空间给作业使用， 以至于存储器中缺乏大的空闲分区，故把它称为是最坏适应算法。实际上，这样的算法未 必是最坏的，它的优点是可使剩下的空闲区不至于太小，产生碎片的可能性最小，对中、 小作业有利。同时，最坏适应分配算法查找效率很高，该算法要求，将所有的空闲分区， 按其容量以从大到小的顺序形成一空闲分区链，查找时，只要看第一个分区能否满足作业 要求即可。"
          },
          {
            "三级标题": "4.3.5 基于索引搜索的动态分区分配算法 一 基于顺序搜索的动态分区分配算法，比较适用于不太大的系统。当系统很大时，系统 中的内存分区可能会很多，相应的空闲分区链就可能很长，这时采用顺序搜索分区方法可 能会很慢。为了提高搜索空闲分区的速度，在大、中型系统中往往会采用基于索引搜索的 动态分区分配算法，目前常用的有快速适应算法、伙伴系统和哈希算法。",
            "正文": "1.快速适应（quickfit)算法 该算法又称为分类搜索法，是将空闲分区根据其容量大小进行分类，对于每一类具有 相同容量的所有空闲分区，单独设立一个空闲分区链表，这样系统中存在多个空闲分区链 表。同时，在内存中设立一张管理索引表，其中的每一个索引表项对应了一种空闲分区类 型，并记录了该类型空闲分区链表表头的指针。空闲分区的分类是根据进程常用的空间大 小进行划分的，如2KB、4KB、8KB等，对于其它大小的分区，如7KB这样的空闲区， 既可以放在8KB的链表中，也可以放在一个特殊的空闲区链表中。 131  计算机操作系统 去寻找到能容纳它的最小空闲区链表；第二步是从链表中取下第一块进行分配即可。另外 该算法在进行空闲分区分配时，不会对任何分区产生分割，所以能保留大的分区，满足对 大空间的需求，也不会产生内存碎片。优点是查找效率高。 该算法的主要缺点在于为了有效合并分区，在分区归还主存时的算法复杂，系统开销 较大。此外，该算法在分配空闲分区时，是以进程为单位的，一个分区只属于一个进程， 因此在为进程所分配的一个分区中，或多或少地存在一定的浪费。这是典型的以空间换时 间的做法。\n\n2.伙伴系统（buddysystem) 该算法规定，无论已分配分区或空闲分区，其大小均为2的k次幂(k为整数，1≤k≤m)。 通常2\"是整个可分配内存的大小（也就是最大分区的大小)。假设系统的可利用空间容量为 2\"个字，则系统开始运行时，整个内存区是一个大小为2\"的空闲分区。在系统运行过程 中，由于不断地划分，将会形成若干个不连续的空闲分区，将这些空闲分区按分区的大小 不同大小的空闲分区形成了k个空闲分区链表。 当需要为进程分配一个长度为n的存储空间时，首先计算一个i值，使2i-<n≤2， 然后在空闲分区大小为2的空闲分区链表中查找。若找到，即把该空闲分区分配给进程。 否则，表明长度为2的空闲分区已经耗尽，则在分区大小为2+的空闲分区链表中寻找。 若存在2+的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对 伙伴，其中的一个分区用于分配，而把另一个加入分区大小为2的空闲分区链表中。若大 小为2i+的空闲分区也不存在，则需要查找大小为2+的空闲分区，若找到则也对其进行 两次分割：第一次，将其分割为大小为2\"+1的两个分区，一个用于分配，一个加入到大小 为2+的空闲分区链表中；第二次，将第一次用于分配的空闲区分割为2的两个分区，一 个用于分配，一个加入到大小为2的空闲分区链表中。若仍然找不到，则继续查找大小为 2\"+3的空闲分区，以此类推。由此可见，在最坏的情况下，可能需要对2*的空闲分区进行 k次分割才能得到所需分区。 与一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并，如回收大小 为2'的空闲分区时，若事先已存在2'的空闲分区，则应将其与伙伴分区合并为大小为2i+1 的空闲分区，若事先已存在2+的空闲分区，又应继续与其伙伴分区合并为大小为2+的 空闲分区，依此类推。 在伙伴系统中，对于一个大小为2*，地址为x的内存块，其伙伴块的地址则用buddyk(x) 表示，其通式为： x+2*(若xMOD2k+1=0) buddy(x)= [x-2*(若xMOD2k+1=2k) 在伙伴系统中，其分配和回收的时间性能取决于查找空闲分区的位置和分割、合并空 闲分区所花费的时间。在回收空闲分区时，需要对空闲分区进行合并，所以其时间性能比 快速适应算法差，但由于它采用了索引搜索算法，比顺序搜索算法好。而其空间性能，由 132  第四章存储器管理 于对空闲分区进行合并，减少了小的空闲分区，提高了空闲分区的可使用率，故优于快速 适应算法，比顺序搜索法略差。 需要指出的是，在当前的操作系统中，普遍采用的是下面将要讲述的基于离散分配方 式的分页和分段机制的虚拟内存机制，该机制较伙伴算法更为合理和高效，但在多处理机 系统中，伙伴系统仍不失为一种有效的内存分配和释放的方法，目前仍被广泛使用。\n\n3.哈希算法 在上述的分类搜索算法和伙伴系统算法中，都是将空闲分区根据分区大小进行分类， 对于每一类具有相同大小的空闲分区，单独设立一个空闲分区链表。在为进程分配空间时， 需要在一张管理索引表中查找到所需空间大小所对应的表项，从中得到对应的空闲分区链 表表头指针，从而通过查找得到一个空闲分区。如果对空闲分区分类较细，则相应索引表 的表项也就较多，因此会显著地增加搜索索引表的表项的时间开销。 哈希算法就是利用哈希快速查找的优点，以及空闲分区在可利用空闲区表中的分布规 律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项记录 了一个对应的空闲分区链表表头指针。 当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算，即得到在哈希 表中的位置，从中得到相应的空闲分区链表，实现最佳分配策略。"
          },
          {
            "三级标题": "4.3.6 动态可重定位分区分配",
            "正文": "1.紧凑 间中。当一台计算机运行了一段时间后，它的内存空间将会被分割成许多小的分区，而缺 乏大的空闲空间。即使这些分散的许多小分区的容量总和大于要装入的程序，但由于这些 分区不相邻接，也无法把该程序装入内存。例如，图4-11(a)中示出了在内存中现有四个互 不邻接的小分区，它们的容量分别为10KB、30KB、14KB和26KB，其总容量是80KB。 但如果现在有一个作业到达，要求获得40KB的内存空间，由于必须为它分配一个连续空 间，故此作业无法装入。这种不能被利用的小分区即是前已提及的“碎片”，或称为“零头”。 操作系统 操作系统 用户程序1 用户程序1 1KB/ 用户程序3 用户程序3 用户程序6 30KB// 用户程序9 用户程序6 /4KB 80KB 用户程序9 26KBTA (a)紧凑前 (b)紧凌后 图4-11紧凑的示意 133  计算机操作系统 若想把大作业装入，可采用的一种方法是：将内存中的所有作业进行移动，使它们全 都相邻接。这样，即可把原来分散的多个空闲小分区拼接成一个大分区，可将一个作业装 入该区。这种通过移动内存中作业的位置，把原来多个分散的小分区拼接成一个大分区的 方法，称为“拼接”或“紧凑”，见图4-11(b)。 虽然“紧凑”能获得大的空闲空间，但也带来了新的问题，即经过紧凑后的用户程序 在内存中的位置发生了变化，此时若不对程序和数据的地址加以修改(变换)，则程序必将 无法执行。为此，在每次“紧凑”后，都必须对移动了的程序或数据进行重定位。为了提 高内存的利用率，系统在运行过程中是经常需要进行“紧凑”的，每“紧凑”一次，就要 对移动了的程序或数据的地址进行修改，这不仅是一件相当麻烦的事情，而且还大大地影 响到系统的效率。下面要介绍的动态重定位方法将能很好地解决此问题。\n\n2.动态重定位 在4.2.1节中所介绍的动态运行时装入的方式中，作业装入内存后的所有地址仍然都是 相对（逻辑）地址。而将相对地址转换为绝对（物理）地址的工作被推迟到程序指令要真正执行 时进行。为使地址的转换不会影响到指令的执行速度，必须有硬件地址变换机构的支持， 即须在系统中增设一个重定位寄存器，用它来存放程序（数据）在内存中的起始地址。程序 在执行时，真正访问的内存地址是相对地址与重定位寄存器中的地址相加而形成的。图4-12 示出了动态重定位的实现原理。地址变换过程是在程序执行期间，随着对每条指令或数据 内存的某处移至另一处时，不需对程序做任何修改，只要用该程序在内存的新起始地址去 置换原来的起始地址即可。 相对地址 重定位寄存器 10000 2500 10000 100 10100 Load 12500 Load12500 12500 2500 W 365 + 365 5000 15000 作业J 主存 处理机一侧|存储器一侧 图4-12动态重定位示意图\n\n3.动态重定位分区分配算法 动态重定位分区分配算法与动态分区分配算法基本上相同，差别仅在于：在这种分配 算法中，增加了紧凑的功能。通常，当该算法不能找到一个足够大的空闲分区以满足用户 需求时，如果所有的小的空闲分区的容量总和大于用户的要求，这时便须对内存进行“紧 凑”，将经“紧凑”后所得到的大空闲分区分配给用户。如果所有的小的空闲分区的容量 总和仍小于用户的要求，则返回分配失败信息。图4-13示出了动态重定位分区分配算法。 134  第四章存储器管理 请求分配 u.size分区 检索空闲分区链（表) 无法分配 否 空闲分区 否 找到大于u.size 返回 总和≥usize？ 的可用区否？ 是 是 进行紧凑形成 按动态分区方式 连续空闲区 进行分配 修改有关的 进行紧凑形成 返回分区号 数据结构 连续空闲区 及首址 图4-13动态分区分配算法流程图 对换（Swapping) 对换技术也称为交换技术，最早用于麻省理工学院的单用户分时系统CTSS中。由于 当时计算机的内存都非常小，为了使该系统能分时运行多个用户程序而引入了对换技术。 系统把所有的用户作业存放在磁盘上，每次只能调入一个作业进入内存，当该作业的一个 时间片用完时，将它调至外存的后备队列上等待，再从后备队列上将另一个作业调入内存。 这就是最早出现的分时系统中所用的对换技术。现在已经很少使用。 由上所述可知，要实现内、外存之间的对换，系统中必须有一台I/O速度较高的外存， 而且其容量也必须足够大，能容纳正在分时运行的所有用户作业，自前最常使用的是大容 量磁盘存储器。下面我们主要介绍目前在多道程序环境中广泛使用的对换技术。"
          },
          {
            "三级标题": "4.4.1 多道程序环境下的对换技术",
            "正文": "1.对换的引入 在多道程序环境下，一方面，在内存中的某些进程由于某事件尚未发生而被阻塞运行， 但它却占用了大量的内存空间，甚至有时可能出现在内存中所有进程都被阻塞，而无可运 行之进程，迫使CPU停止下来等待的情况；另一方面，却又有着许多作业，因内存空间不 足，一直驻留在外存上，而不能进入内存运行。显然这对系统资源是一种严重的浪费， 且使系统吞吐量下降。为了解决这一问题，在系统中又增设了对换（也称交换)设施。所谓 “对换”，是指把内存中暂时不能运行的进程或者暂时不用的程序和数据换出到外存上， 以便腾出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据换入 135"
          }
        ]
      },
      {
        "二级标题": "4.4_对换(Swapping)",
        "三级内容": [
          {
            "三级标题": "4.4.1 多道程序环境下的对换技术",
            "正文": "1.对换的引入 在多道程序环境下，一方面，在内存中的某些进程由于某事件尚未发生而被阻塞运行， 但它却占用了大量的内存空间，甚至有时可能出现在内存中所有进程都被阻塞，而无可运 行之进程，迫使CPU停止下来等待的情况；另一方面，却又有着许多作业，因内存空间不 足，一直驻留在外存上，而不能进入内存运行。显然这对系统资源是一种严重的浪费， 且使系统吞吐量下降。为了解决这一问题，在系统中又增设了对换（也称交换)设施。所谓 “对换”，是指把内存中暂时不能运行的进程或者暂时不用的程序和数据换出到外存上， 以便腾出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据换入 135  计算机操作系统 内存。对换是改善内存利用率的有效措施，它可以直接提高处理机的利用率和系统的吞 吐量。 自从20世纪60年代初期出现“对换”技术后，便引起了人们的重视。在早期的UNIX 系统中已引入了对换功能，该功能一直保留至今，各个UNIX版本实现对换功能的方法也 大体上是一样的，即在系统中设置一个对换进程，由它将内存中暂时不能运行的进程调出 到磁盘的对换区；同样也由该进程将磁盘上已具备运行条件的进程调入内存。在Windows OS中也具有对换功能。如果一个新进程在装入内存时发现内存不足，可以将已在内存中的 老进程调至磁盘，腾出内存空间。由于对换技术的确能有效地改善内存的利用率，故现在 已被广泛地应用于OS中。\n\n2.对换的类型 在每次对换时，都是将一定数量的程序或数据换入或换出内存。根据每次对换时所对 换的数量，可将对换分为如下两类：\n\n（1）整体对换。在第三章中介绍处理机调度时已经说明了，处理机中级调度实际上就 是存储器的对换功能，其目的是用来解决内存紧张问题，并可进一步提高内存的利用率和 系统的吞吐量。由于在中级调度中对换是以整个进程为单位的，故称之为“进程对换”或 “整体对换”。这种对换被广泛地应用于多道程序系统中，并作为处理机中级调度。\n\n（2）页面（分段）对换。如果对换是以进程的一个“页面”或“分段”为单位进行的，则 在此，我们只介绍进程对换，而分页或分段对换，将放在虚拟存储器中介绍。为了实现进 程对换，系统必须能实现三方面的功能：对对换空间的管理、进程的换出和进程的换入。"
          },
          {
            "三级标题": "4.4.2 对换空间的管理",
            "正文": "1.对换空间管理的主要目标 在具有对换功能的OS中，通常把磁盘空间分为文件区和对换区两部分。 1）对文件区管理的主要目标 文件区占用磁盘空间的大部分，用于存放各类文件。由于通常的文件都是较长时间地 驻留在外存上，对它访问的频率是较低的，故对文件区管理的主要目标是提高文件存储空 间的利用率，然后才是提高对文件的访问速度。因此，对文件区空间的管理采取离散分配 方式。 2）对对换空间管理的主要目标 对换空间只占用磁盘空间的小部分，用于存放从内存换出的进程。由于这些进程在对 换区中驻留的时间是短暂的，而对换操作的频率却较高，故对对换空间管理的主要目标， 是提高进程换入和换出的速度，然后才是提高文件存储空间的利用率。为此，对对换区空 间的管理采取连续分配方式，较少考虑外存中的碎片问题。\n\n2.对换区空闲盘块管理中的数据结构 为了实现对对换区中的空闲盘块的管理，在系统中应配置相应的数据结构，用于记录 外存对换区中的空闲盘块的使用情况。其数据结构的形式与内存在动态分区分配方式中所 136  第四章存储器管理 用数据结构相似，即同样可以用空闲分区表或空闲分区链。在空闲分区表的每个表目中， 应包含两项：对换区的首址及其大小，分别用盘块号和盘块数表示。\n\n3.对换空间的分配与回收 由于对换分区的分配采用的是连续分配方式，因而对换空间的分配与回收与动态分区 方式时的内存分配与回收方法雷同。其分配算法可以是首次适应算法、循环首次适应算法 或最佳适应算法等。具体的分配操作也与图4-8中内存的分配过程相同。对换区的回收操 作可分为四种情况：\n\n（1）回收分区与插入点的前一个空闲分区F相邻接；\n\n（2）回收分区与插入点的后一个空闲分区F2相邻接；\n\n（3）回收分区同时与插入点的前、后两个分区邻接；\n\n（4）回收分区既不与F邻接，又不与F2邻接。 对上述这几种情况的处理方法也与动态分区方式相同，故在这里不再赘述。"
          },
          {
            "三级标题": "4.4.3 进程的换出与换入 当内核因执行某操作而发现内存不足时，例如，当一进程由于创建子进程而需要更多 的内存空间，但又无足够的内存空间等情况发生时，便调用（或换醒）对换进程，它的主要 任务是实现进程的换出和换入。",
            "正文": "1.进程的换出 对换进程在实现进程换出时，是将内存中的某些进程调出至对换区，以便腾出内存空 间。换出过程可分为以下两步：\n\n（1）选择被换出的进程。对换进程在选择被换出的进程时，将检查所有驻留在内存中 的进程，首先选择处于阻塞状态或睡眠状态的进程，当有多个这样的进程时，应当选择优 先级最低的进程作为换出进程。在有的系统中，为了防止低优先级进程在被调入内存后很 快又被换出，还需考虑进程在内存的驻留时间。如果系统中已无阻塞进程，而现在的内存 空间仍不足以满足需要，便选择优先级最低的就绪进程换出。\n\n(2）进程换出过程。应当注意，在选择换出进程后，在对进程换出时，只能换出非共 出。在进行换出时，应先申请对换空间，若申请成功，就启动磁盘，将该进程的程序和数 据传送到磁盘的对换区上。若传送过程未出现错误，便可回收该进程所占用的内存空间， 并对该进程的进程控制块和内存分配表等数据结构做相应的修改。若此时内存中还有可换 出的进程，则继续执行换出过程，直到内存中再无阻塞进程为止。\n\n2.进程的换入 对换进程将定时执行换入操作，它首先查看PCB集合中所有进程的状态，从中找出 “就绪”状态但已换出的进程。当有许多这样的进程时，它将选择其中已换出到磁盘上时 间最久（必须大于规定时间，如2s)的进程作为换入进程，为它申请内存。如果申请成功， 可直接将进程从外存调入内存；如果失败，则需先将内存中的某些进程换出，腾出足够的 内存空间后，再将进程调入。 在对换进程成功地换入一个进程后，若还有可换入的进程，则再继续执行换入换出过 137  计算机操作系统 态的进程为止，或者已无足够的内存来换入进程，此时对换进程才停止换入。 由于要交换一个进程需要很多的时间，因此，对于提高处理机的利用率而言，它并不 是一个非常有效的解决方法。目前用得较多的对换方案是，在处理机正常运行时，并不启 动对换程序。但如果发现有许多进程在运行时经常发生缺页且显现出内存紧张的情况，才 启动对换程序，将一部分进程调至外存。如果发现所有进程的缺页率都已明显减少，而系 统的吞吐量已下降时，则可暂停运行对换程序。 1/4.5分页存储管理方式 大块空间，但须为之付出很大开销。如果允许将一个进程直接分散地装入到许多不相邻接 的分区中，便可充分地利用内存空间，而无须再进行“紧凑”。基于这一思想而产生了离散 分配方式。根据在离散分配时所分配地址空间的基本单位的不同，又可将离散分配分为以 下三种：\n\n(1）分页存储管理方式。在该方式中，将用户程序的地址空间分为若干个固定大小的 区域，称为“页”或“页面”。典型的页面大小为1KB。相应地，也将内存空间分为若干 个物理块或页框（frame)，页和块的大小相同。这样可将用户程序的任一页放入任一物理块 中，实现了离散分配。\n\n（2）分段存储管理方式。这是为了满足用户要求而形成的一种存储管理方式。它把用 分配时，以段为单位，这些段在内存中可以不相邻接，所以也同样实现了离散分配。\n\n(3）段页式存储管理方式。这是分页和分段两种存储管理方式相结合的产物。它同时 具有两者的优点，是目前应用较厂泛的一种存储管理方式。"
          },
          {
            "三级标题": "4.5.1 分页存储管理的基本方法",
            "正文": "1.页面和物理块\n\n（1）页面。分页存储管理将进程的逻辑地址空间分成若干个页，并为各页加以编号， 从0开始，如第0页、第1页等。相应地，也把内存的物理地址空间分成若干个块，同样 也为它们加以编号，如0#块、1#块等等。在为进程分配内存时，以块为单位，将进程中 的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一 块，而形成了不可利用的碎片，称之为“页内碎片”。\n\n(2）页面大小。在分页系统中，若选择过小的页面大小，虽然一方面可以减小内存碎 片，起到减少内存碎片总空间的作用，有利于内存利用率的提高，但另一方面却会造成每 个进程占用较多的页面，从而导致进程的页表过长，占用大量内存。此外，还会降低页面 换进换出的效率。然而，如果选择的页面过大，虽然可以减少页表的长度，提高页面换进 换出的速度，但却又会使页内碎片增大。因此，页面的大小应选择适中，且页面大小应是 2的幂，通常为1KB～8KB。 138"
          }
        ]
      },
      {
        "二级标题": "4.5_分页存储管理方式",
        "三级内容": [
          {
            "三级标题": "4.5.1 分页存储管理的基本方法",
            "正文": "1.页面和物理块\n\n（1）页面。分页存储管理将进程的逻辑地址空间分成若干个页，并为各页加以编号， 从0开始，如第0页、第1页等。相应地，也把内存的物理地址空间分成若干个块，同样 也为它们加以编号，如0#块、1#块等等。在为进程分配内存时，以块为单位，将进程中 的若干个页分别装入到多个可以不相邻接的物理块中。由于进程的最后一页经常装不满一 块，而形成了不可利用的碎片，称之为“页内碎片”。\n\n(2）页面大小。在分页系统中，若选择过小的页面大小，虽然一方面可以减小内存碎 片，起到减少内存碎片总空间的作用，有利于内存利用率的提高，但另一方面却会造成每 个进程占用较多的页面，从而导致进程的页表过长，占用大量内存。此外，还会降低页面 换进换出的效率。然而，如果选择的页面过大，虽然可以减少页表的长度，提高页面换进 换出的速度，但却又会使页内碎片增大。因此，页面的大小应选择适中，且页面大小应是 2的幂，通常为1KB～8KB。 138  第四章 存储器管理\n\n2.地址结构 分页地址中的地址结构如下： 31\n\n12 11 0 位移量W 页号P 它包含两部分内容：前一部分为页号P，后一部分为位(偏)移量W，即页内地址。图 中的地址长度为32位，其中0～11位为页内地址，即每页的大小为4KB；12～31位为页 号，地址空间最多允许有1M页。 对某特定机器，其地址结构是一定的。若给定一个逻辑地址空间中的地址为A，页面 的大小为L，则页号P和页内地址d可按下式求得： [A] P =INT d=[A] MOD L [L 其中，INT是整除函数，MOD是取余函数。例如，其系统的页面大小为1KB，设A=2170B， 则由上式可以求得P=2，d=122。\n\n3.页表 仍然能够正确地运行，即能在内存中找到每个页面所对应的物理块，系统又为每个进程建 立了一张页面映像表，简称页表。在进程地址空间内的所有页（0～n)，依次在页表中有一 页表项，其中记录了相应页在内存中对应的物理块号，见图4-14的中间部分。在配置了页 表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作 用是实现从页号到物理块号的地址映射。 用户程序 内存 0页 页号块号 1页 0 2 2页 1 3 3页 2 6 4页 3 8 5页 4 9 5 n页 10 图4-14页表的作用 即使在简单的分页系统中，也常在页表的表项中设置一存取控制字段，用于对该存储 块中的内容加以保护。当存取控制字段仅有一位时，可用来规定该存储块中的内容是允许 读/写还是只读；若存取控制字段为二位，则可规定为读/写、只读和只执行等存取方式。如 果有一进程试图去写一个只允许读的存储块时，将引起操作系统的一次中断。如果要利用 139  计算机操作系统 分页系统去实现虚拟存储器，则还须增设一个数据项。我们将在本章后面做详细介绍。"
          },
          {
            "三级标题": "4.5.2 地址变换机构 为了能将用户地址空间中的逻辑地址转换为内存空间中的物理地址，在系统中必须设 置地址变换机构。该机构的基本任务是实现从逻辑地址到物理地址的转换。由于页内地址 和物理地址是一一对应的（例如，对于页面大小是1KB的页内地址是0～1023，其相应的 物理块内的地址也是0～1023，无需再进行转换)，因此，地址变换机构的任务实际上只是 将逻辑地址中的页号转换为内存中的物理块号。又因为页面映射表的作用就是用于实现从 页号到物理块号的变换，因此，地址变换任务是借助于页表来完成的。",
            "正文": "1.基本的地址变换机构 进程在运行期间，需要对程序和数据的地址进行变换，即将用户地址空间中的逻辑地 址变换为内存空间中的物理地址，由于它执行的频率非常高，每条指令的地址都需要进行 变换，因此需要采用硬件来实现。页表功能是由一组专门的寄存器来实现的。一个页表项 用一个寄存器。由于寄存器具有较高的访问速度，因而有利于提高地址变换的速度；但由 于寄存器成本较高，且大多数现代计算机的页表又可能很大，使页表项的总数可达几千甚 至几十万个，显然这些页表项不可能都用寄存器来实现。因此，页表大多驻留在内存中。 在系统中只设置一个页表寄存器PTR(Page-TableRegister)，在其中存放页表在内存的始址 和页表的长度。平时，进程未执行时，页表的始址和页表长度存放在本进程的PCB中。当 调度程序调度到某进程时，才将这两个数据装入页表寄存器中。因此，在单处理机环境下， 虽然系统中可以运行多个进程，但只需一个页表寄存器。 当进程要访问某个逻辑地址中的数据时，分页地址变换机构会自动地将有效地址（相对 地址)分为页号和页内地址两部分，再以页号为索引去检索页表。查找操作由硬件执行。在 执行检索之前，先将页号与页表长度进行比较，如果页号大于或等于页表长度，则表示本 次所访问的地址已超越进程的地址空间。于是，这一错误将被系统发现，并产生一地址越 界中断。若未出现越界错误，则将页表始址与页号和页表项长度的乘积相加，便得到该表 项在页表中的位置，于是可从中得到该页的物理块号，将之装入物理地址寄存器中。与此 同时，再将有效地址寄存器中的页内地址送入物理地址寄存器的块内地址字段中。这样便 完成了从逻辑地址到物理地址的变换。图4-15示出了分页系统的地址变换机构。 越界中断 页表寄存器 逻辑地址 页表始址页表长度 > 页号（3）页内地址 页号 块号 0 1 1 2 3 b 物理地址 页表 图4-15分页系统的地址变换机构 140  第四章 存储器管理\n\n2.具有快表的地址变换机构 由于页表是存放在内存中的，这使CPU在每存取一个数据时，都要两次访问内存。第 一次是访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移量W拼接， 以形成物理地址。第二次访问内存时，才是从第一次所得地址中获得所需数据（或向此地址 中写入数据）。因此，采用这种方式将使计算机的处理速度降低近1/2。可见，以此高昂代 价来换取存储器空间利用率的提高，是得不偿失的。 为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的特殊高速 缓冲寄存器，又称为“联想寄存器”（AssociativeMemory)，或称为“快表”，在IBM系统 中又取名为TLB(TranslationLookasideBuffer)，用以存放当前访问的那些页表项。此时的 地址变换过程是：在CPU给出有效地址后，由地址变换机构自动地将页号P送入高速缓冲 寄存器，并将此页号与高速缓存中的所有页号进行比较，若其中有与此相匹配的页号，便 表示所要访问的页表项在快表中。于是，可直接从快表中读出该页所对应的物理块号，并 送到物理地址寄存器中。如在快表中未找到对应的页表项，则还须再访问内存中的页表， 找到后，把从页表项中读出的物理块号送往地址寄存器；同时，再将此页表项存入快表的 一个寄存器单元中，亦即，重新修改快表。但如果联想寄存器已满，则OS必须找到一个 老的且已被认为是不再需要的页表项，将它换出。图4-16示出了具有快表的地址变换机构。 页表寄存器 逻辑地址L 页表始址页表长度 > 越界中断 页号（3）页内地址 页号 块号 页号块号 0 1 b 入 2 寄 存 3 器 快表 页表 bd] 物理地址 图4-16具有快表的地址变换机构 由于成本的关系，快表不可能做得很大，通常只存放16～512个页表项，这对中、小 型作业来说，已有可能把全部页表项放在快表中；但对于大型作业而言，则只能将其一部 分页表项放入其中。由于对程序和数据的访问往往带有局限性，因此，据统计，从快表中 能找到所需页表项的概率可达90%以上。这样，由于增加了地址变换机构而造成的速度损 失可减少到10%以下，达到了可接受的程度。"
          },
          {
            "三级标题": "4.5.4 两级和多级页表 现代的大多数计算机系统都支持非常大的逻辑地址空间(22B～2°B)。在这样的环境 下，页表就变得非常大，要占用相当大的内存空间。例如，对于一个具有32位逻辑地址空 间的分页系统，规定页面大小为4KB即2°B，则在每个进程页表中的页表项数可达1MB 之多。又因为每个页表项占用一个字节，故每个进程仅仅其页表就要占用1MB的内存空 间，而且还要求是连续的。显然这是不现实的，我们可以采用这样两个方法来解决这一问 题：①对于页表所需的内存空间，可采用离散分配方式，以解决难以找到一块连续的大内 存空间的问题；②只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上， 需要时再调入。",
            "正文": "1.两级页表（Two-LevelPageTable) 针对难于找到大的连续的内存空间来存放页表的问题，可利用将页表进行分页的方法， 使每个页面的大小与内存物理块的大小相同，并为它们进行编号，即依次为0#页、1#页，， n#页，然后离散地将各个页面分别存放在不同的物理块中。同样，也要为离散分配的页表 142  第四章存储器管理 再建立一张页表，称为外层页表(OuterPageTable)，在每个页表项中记录了页表页面的物理 块号。下面我们仍以前面的32位逻辑地址空间为例来说明。当页面大小为4KB时(12位)， 若采用一级页表结构，应具有20位的页号，即页表项应有1M个；在采用两级页表结构时， 再对页表进行分页，使每页中包含2（即1024)个页表项，最多允许有21个页表分页；或 者说，外层页表中的外层页内地址P2为10位，外层页号P1也为10位。此时的逻辑地址结 构如图4-17所示。 外层页号 外层页内地址 页内地址 P P2 d 22 21 12 11 0 图4-17两级页表结构 由图可以看出，在页表的每个表项中，存放的是进程的某页在内存中的物理块号，如 0#页存放在1#物理块中，1#页存放在4#物理块中。而在外层页表的每个页表项中所存放 的是某页表分页的首址，如0#页表存放在1011#物理块中。我们可以利用外层页表和页表 这两级页表来实现进程从逻辑地址到内存中物理地址的变换。 为了方便实现地址变换，在地址变换机构中，同样需要增设一个外层页表寄存器，用 于存放外层页表的始址，并利用逻辑地址中的外层页号作为外层页表的索引，从中找到指 定页表分页的始址，再利用P2作为指定页表分页的索引，找到指定的页表项，其中即含有 该页在内存的物理块号，用该块号P和页内地址d即可构成访问的内存物理地址。图4-18 示出了两级页表时的地址变换机构。 0#页表 0 0 1011 01 1 1 1078 1 4 2 2 2 6 3 ： ： 4 5 N023 6 1#页表 7 114 1 115 ： 1742 ： 114 外部页表 1023 115 n#页表 0 1468 1 1468 2 ： 1023 内存空间 图4-18具有两级页表的地址变换机构 上述对页表施行离散分配的方法，虽然解决了对于天页表无需大片连续存储空间的问 题，但并未解决用较少的内存空间去存放大页表的问题。换言之，只用离散分配空间的办 法并未减少页表所占用的内存空间。能够用较少的内存空间存放页表的唯一方法是，仅把 143  计算机操作系统 当前需要的一批页表项调入内存，以后再根据需要陆续调入。在采用两级页表结构的情况 下，对于正在运行的进程，必须将其外层页表调入内存，而对于页表则只需调入一页或几 页。为了表征某页的页表是否已经调入内存，还应在外层页表项中增设一个状态位S，其 值若为0，表示该页表分页不在内存中，否则说明其分页已调入内存。进程运行时，地址 变换机构根据逻辑地址中的P去查找外层页表；若所找到的页表项中的状态位为0，则产 生一个中断信号，请求OS将该页表分页调入内存。关于请求调页的详细情况，将在虚拟 存储器一章中介绍。\n\n2.多级页表 对于32位的机器，采用两级页表结构是合适的，但对于64位的机器，采用两级页表 假定仍按物理块的大小(2位）来划分页表，则将余下的42位用于外层页号。此时在外层页 表中可能有4096G个页表项，要占用16384GB的连续内存空间。这样的结果显然是不能 令人接受的。因此，必须采用多级页表，将外层页表再进行分页，也就是将各分页离散地 装入到不相邻接的物理块中，再利用第2级的外层页表来映射它们之间的关系。 对于64位的计算机，如果要求它能支持2（=1844744TB）规模的物理存储空间，则 即使是采用三级页表结构也是难以办到的，而在当前的实际应用中也无此必要。故在近两 年推出的64位OS中，把可直接寻址的存储器空间减少为45位长度(即2)左右，这样便 可利用三级页表结构来实现分页存储管理。"
          },
          {
            "三级标题": "4.5.5 反置页表（lnvertedPageTable)",
            "正文": "1.反置页表的引入 在分页系统中，为每个进程配置了一张页表，进程逻辑地址空间中的每一页，在页表 空间，引入了反置页表。一般页表的页表项是按页号进行排序的，页表项中的内容是物理 块号。而反置页表则是为每一个物理块设置一个页表项，并将它们按物理块的编号排序， 其中的内容则是页号和其所隶属进程的标识符。在IBM公司推出的许多系统中都采用了反 置页表，如AS/400、IBMRISCSystem和IBMRT等系统。\n\n2.地址变换 在利用反置页表进行地址变换时，是根据进程标识符和页号，去检索反置页表。如果 检索到与之匹配的页表项，则该页表项（中）的序号i便是该页所在的物理块号，可用该块号 与页内地址一起构成物理地址送内存地址寄存器。若检索了整个反置页表仍未找到匹配的 页表项，则表明此页尚未装入内存。对于不具有请求调页功能的存储器管理系统，此时则 表示地址出错。对于具有请求调页功能的存储器管理系统，此时应产生请求调页中断，系 统将把此页调入内存。 虽然反置页表可有效地减少页表占用的内存，例如，对于一个具有64MB的机器，如 果页面大小为4KB，那么反置页表只占用64KB内存。然而在该表中只包含了已经调入内 存的页面，并未包含尚未调入内存的页面。因此，还必须为每个进程建立一个外部页表 144  第四章存储器管理 (ExtermalPageTable)。该页表与传统的页表一样，当所访问的页面在内存时，并不需要访 问外部页表，仅当发现所需之页面不在内存时，才使用它。在页表中包含了各个页在外存 的物理位置，通过它可将所需之页面调入内存。 由于在反置页表中是为每一个物理块设置一个页表项，当内存容量很大时，页表项的 数目还是会非常大的。要利用进程标识符和页号去检索这样大的一张线性表是相当费时的。 于是可利用Hash算法来进行检索，这样可以很快地找到在反置页表中的相应页表项。不过 在采用Hash算法时，可能会出现所谓的“地址冲突”，即有多个逻辑地址被映射到同一个 Hash表项上，必须妥善解决这一问题。我们将在文件系统中作进一步的介绍。\n\n4.6分段存储管理方式 存储管理方式随着OS的发展也在不断地发展。当OS由单道向多道发展时，存储管理 存储管理方式又从固定分区分配，发展到动态分区分配。为了能更好地提高内存的利用率， 进而又从连续分配方式发展到离散分配方式一分页存储管理方式。如果说，推动上述发 展的主要动力都是直接或间接地出于提高内存利用率的目的，那么，引入分段存储管理方 式的目的，则主要是为了满足用户（程序员）在编程和使用上多方面的要求，其中有些要求 是其它几种存储管理方式所难以满足的。因此，这种存储管理方式已成为当今所有存储管 理方式的基础，许多高级语言和C语言的编译程序也都支持分段存储管理方式。"
          },
          {
            "三级标题": "4.6.1 分段存储管理方式的引入 为什么要引入分段存储管理方式，可从下面两个方面说明：一方面是由于通常的程序 个段大多是一个相对独立的逻辑单位；另一方面，实现和满足信息共享、信息保护、动态 链接以及信息的动态增长等需要，也都是以段为基本单位的。更具体地说，分段存储管理 方式更符合用户和程序员如下多方面的需要。",
            "正文": "1.方便编程 通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都从0开始编址，并 有自己的名字和长度。因此，程序员们都迫切地需要访问的逻辑地址是由段名（段号）和段 内偏移量（段内地址)决定的，这不仅可以方使程序员编程，也可使程序非常直观，更具可 读性。例如，下述的两条指令便使用段名和段内地址： LOAD1, [A]1 <D); STORE 1，[B]I(C>; 其中，前一条指令的含义是，将分段A中D单元内的值读入寄存器1；后一条指令的含义 是，将寄存器1的内容存入B分段的C单元中。\n\n2.信息共享 在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，为了共享某个 过程、函数或文件。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的逻辑 145"
          }
        ]
      },
      {
        "二级标题": "4.6_分段存储管理方式",
        "三级内容": [
          {
            "三级标题": "4.6.1 分段存储管理方式的引入 为什么要引入分段存储管理方式，可从下面两个方面说明：一方面是由于通常的程序 个段大多是一个相对独立的逻辑单位；另一方面，实现和满足信息共享、信息保护、动态 链接以及信息的动态增长等需要，也都是以段为基本单位的。更具体地说，分段存储管理 方式更符合用户和程序员如下多方面的需要。",
            "正文": "1.方便编程 通常，用户把自己的作业按照逻辑关系划分为若干个段，每个段都从0开始编址，并 有自己的名字和长度。因此，程序员们都迫切地需要访问的逻辑地址是由段名（段号）和段 内偏移量（段内地址)决定的，这不仅可以方使程序员编程，也可使程序非常直观，更具可 读性。例如，下述的两条指令便使用段名和段内地址： LOAD1, [A]1 <D); STORE 1，[B]I(C>; 其中，前一条指令的含义是，将分段A中D单元内的值读入寄存器1；后一条指令的含义 是，将寄存器1的内容存入B分段的C单元中。\n\n2.信息共享 在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，为了共享某个 过程、函数或文件。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的逻辑 145  计算机操作系统 意义，这样，一个可被共享的过程往往可能需要占用数十个页面，这为实现共享增加了困 难。如前所述，段可以是信息的逻辑单位，因此，我们可以为该被共享过程建立一个独立 的段，这就极大地简化了共享的实现。为了实现段的共享，存储管理应能与用户程序分段 的组织方式相适应，有关段共享的具体实现方法将在下一节中介绍。\n\n3.信息保护 信息保护同样是以信息的逻辑单位为基础的，而且经常是以一个过程、函数或文件为 基本单位进行保护的。例如，我们希望函数A仅允许进程执行，而不允许读，更不允许写， 那么，我们只须在包含了函数A的这个段上标上只执行标志即可。但是在分页系统中，函 数A可能要占用若干个页面，而且其中的第一个和最后一个页面还会装有其它程序段的数 据，它们可能有着不同的保护属性，如可以允许进程读写，这样就很难对这些页面实施统 一的保护，因此，分段管理方式能更有效和方便地实现对信息的保护功能。\n\n4.动态增长 在实际应用中，往往存在着一些段，尤其是数据段，在它们的使用过程中，由于数据 量的不断增加，而使数据段动态增长，相应地它所需要的存储空间也会动态增加。然而， 对于数据段究竟会增长到多大，事先又很难确切地知道。对此，很难采取预先多分配的方 法进行解决。前述的其它几种存储管理方式都难以应付这种动态增长的情况，而分段存储 管理方式却能较好地解决这一问题。\n\n5.动态链接 正要运行的目标程序装入内存，也就是说，动态链接在作业运行之前，并不是把所有的目 内存，即启动运行。而在程序运行过程中，当需要调用某个目标程序时，才将该段（目标程 序）调入内存并进行链接。可见，动态链接要求的是以目标程序（即段）作为链接的基本单位， 因此，分段存储管理方式非常适合于动态链接。"
          },
          {
            "三级标题": "4.6.2 分段系统的基本原理",
            "正文": "1.分段 在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑 信息。例如，有主程序段MAIN、子程序段X、数据段D及栈段S等，如图4-19所示。每 个段都有自已的名字。为了实现简单起见，通常可用一个段号来代替段名，每个段都从0 开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，因此 各段的长度并不相等。整个作业的地址空间由于被分成多个段，所以呈现出二维特性，亦 即，每个段既包含了一部分地址空间，又标识了逻辑关系。其逻辑地址由段号（段名）和段 内地址所组成。 分段地址中的地址具有如下结构： 段号 段内地址 31 1615 146  第四章存储器管理 在该地址结构中，允许一个作业最长有64K个段，每个段的最大长度为64KB。 分段方式已得到许多编译程序的支持，编译程序能自动地根据源程序的情况产生若干 个段。例如，Pascal编译程序可以为全局变量、用于存储相应参数及返回地址的过程调用 栈、每个过程或函数的代码部分、每个过程或函数的局部变量等，分别建立各自的段。类 似地，Fortran编译程序可以为公共块（Commonblock)建立单独的段，也可以为数组分配一 个单独的段。装入程序将装入所有这些段，并为每个段赋予一个段号。\n\n2.段表 在前面所介绍的动态分区分配方式中，系统为整个进程分配一个连续的内存空间。而 离散地装入内存中不同的分区中。为保证程序能正常运行，就必须能从物理内存中找出每 个逻辑段所对应的位置。为此，在系统中，类似于分页系统，需为每个进程建立一张段映 射表，简称“段表”。每个段在表中占有一个表项，其中记录了该段在内存中的起始地址（又 称为“基址”）和段的长度，如图4-19所示。段表可以存放在一组寄存器中，以利于提高 地址转换速度。但更常见的方法是将段表放在内存中。在配置了段表后，执行中的进程可 通过查找段表，找到每个段所对应的内存区。可见，段表是用于实现从逻辑段到物理内存 区的映射的。 作业空间 内存空间 (MAIN)=1 段表 40K 段号 段长 基址 30K (MAIN)=0 (X)=1 N 30K 30K 40K 》 80K 20K 20K 80K (X)=1 (D)=2 30K 15K 120K 120K D(1)=2 10K 150K 15K 15K (S)=3 150K (S)=3 10K 10K 图4-19利用段表实现地址映射\n\n3.地址变换机构 为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于 存放段表始址和段表长度TL。在进行地址变换时，系统将逻辑地址中的段号与段表长度 TL进行比较。若S>TL，表示段号太大，是访问越界，于是产生越界中断信号。若未越界， 则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的 起始地址。然后，再检查段内地址d是否超过该段的段长SL。若超过，即d>SL，同样发 出越界中断信号。若未越界，则将该段的基址d与段内地址相加，即可得到要访问的内存 物理地址。图4-20示出了分段系统的地址变换过程。 147  计算机操作系统 控制寄存器 段号S 位移量W 越界 段表始址段表长度 2 100 有效地址 段号段长 基址 0 1K6K ? 6004K 2 5008K 8192 物理地址 2009200 3 8K 8292 8692 主存 图4-20分段系统的地址变换过程 像分页系统一样，当段表放在内存中时，每要访问一个数据，都须访问两次内存，从 而成倍地降低了计算机的速率。解决的方法和分页系统类似，也增设一个联想存储器，用 于保存最近常用的段表项。一般情况下，由于是段比页大，因而段表项的数目比页表项的 数目少，其所需的联想存储器也相对较小，所以可以显著地减少存取数据的时间，与没有 地址变换的常规存储器相比而言，其存取速度约慢10%～15%。\n\n4.分页和分段的主要区别 由上所述不难看出，分页和分段系统有许多相似之处。比如，两者都采用离散分配方 式，且都是通过地址映射机构实现地址变换。但在概念上两者完全不同，主要表现在下述 三个方面：\n\n（1）页是信息的物理单位。采用分页存储管理方式是为实现离散分配方式，以消减内 存的外零头，提高内存的利用率。或者说，分页仅仅只是系统管理上的需要，完全是系统 的行为，对用户是不可见的。分段存储管理方式中的段则是信息的逻辑单位，它通常包含 的是一组意义相对完整的信息。分段的目的主要在于能更好地满足用户的需要。\n\n(2）页的大小固定且由系统决定。在采用分页存储管理方式的系统中，在硬件结构上， 就把用户程序的逻辑地址划分为页号和页内地址两部分，也就是说是直接由硬件实现的， 因而在每个系统中只能有一种大小的页面。而段的长度却不固定，决定于用户所编写的程 序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。\n\n(3）分页的用户程序地址空间是一维的。分页完全是系统的行为，故在分页系统中， 用户程序的地址是属于单一的线性地址空间，程序员只需利用一个记忆符即可表示一个地 址。而分段是用户的行为，故在分段系统中，用户程序的地址空间是二维的，程序员在标 识一个地址时，既需给出段名，又需给出段内地址。"
          },
          {
            "三级标题": "4.6.3 信息共享 分段系统的一个突出优点，是易于实现段的共享，即允许若干个进程共享一个或多个 148  第四章存储器管理 分段，且对段的保护也十分简单易行。",
            "正文": "1.分页系统中对程序和数据的共享 在分页系统中，虽然也能实现对程序和数据的共享，但远不如分段系统来得方便。我 们通过一个例子来说明这个问题。例如，有一个多用户系统，可同时接纳40个用户，他们 的（Reentrant)，则无论是在分页系统还是在分段系统中，该代码都能被共享，在内存中只需 保留一份文本编辑程序的副本，此时所需的内存空间仅为1760KB（40×40+160)，而不是 8000KB。假定每个页面的大小为4KB，那么，160KB的代码将占用40个页面，数据区 占10个页面。为实现代码的共享，应在每个进程的页表中都建立40个页表项，它们的物 理块号都是21#～60#。在每个进程的页表中，还须为自己的数据区建立页表项，它们的物 理块号分别是61#～70#、71#～80#、81#～90#，，等等。图4-21是分页系统中共享editor 的示意图。 进程1 页表 ed1 21 主存 ed 2 22 ： ed40 60 data1 61 Ipa ed2 22 data40 70 ed40 60 进程2 页表 data 1 61 ed1 21 ： ed 2 22 data10 70 ： data 1 71 ed 40 60 data1 71 data10 data40 80 图4-21分页系统中共享editor的示意图\n\n2.分段系统中程序和数据的共享 在分段系统中，由于是以段为基本单位的，不管该段有多大，我们都只需为该段设置 一个段表项，因此使实现共享变得非常容易。我们仍以共享editor为例，此时只需在（每个） 进程1和进程2的段表中，为文本编辑程序设置一个段表项，让段表项中的基址(80)指向 editor程序在内存的起始地址。图4-22是分段系统中共享editor的示意图。 可重入代码(ReentrantCode)又称为“纯代码”（PureCode)，是一种允许多个进程同时 访问的代码。为使各个进程所执行的代码完全相同，绝对不允许可重入代码在执行中有任 何改变。因此，可重入代码是一种不允许任何进程对它进行修改的代码。但事实上，大多 149  计算机操作系统 数代码在执行时都可能有些改变，例如，用于控制程序执行次数的变量以及指针、信号量 及数组等。为此，在每个进程中，都必须配以局部数据区，把在执行中可能改变的部分拷 贝到该数据区，这样，程序在执行时，只需对该数据区(属于该进程私有)中的内容进行修 改，并不去改变共享的代码，这时的可共享代码即成为可重入代码。 段表 进程1 段长 基址 80 editor editor 160 80 240 data 1 data 1 40 240 280 ： 进程2 380 editor 160 data 2 80 420 data2 40 380 ： 图4-22分段系统中共享editor的示意图"
          },
          {
            "三级标题": "4.6.4 段页式存储管理方式 分页系统以页面作为内存分配的基本单位，能有效地提高内存利用率，而分段系统以 段作为内存分配的基本单位，它能够更好地满足用户多方面的需要。如果能对两种存储管 理方式“各取所长”，则可形成一种新的存储器管理方式一段页式存储管理方式。这种新 的系统既具有分段系统的便于实现、分段可共享、易于保护、可动态链接等一系列优点， 又能像分页系统那样，很好地解决内存的外部碎片问题。",
            "正文": "1.基本原理 段页式系统的基本原理是分段和分页原理的结合，即先将用户程序分成若干个段，再 把每个段分成若干个页，并为每一个段赋予一个段名。图4-23（a)示出了一个作业地址空间 的结构。该作业有三个段：主程序段、子程序段和数据段；页面大小为4KB。在段页式系 统中，其地址结构由段号、段内页号及页内地址三部分所组成，如图4-23(b)所示。 主程序段 子程序段 数据段 00 0 0 4K 4K 4K 8K 8K 10K 12K 12K 15K 16K (a) 段号(S) 段内页号(P) 页内地址(W) (b) 图4-23作业地址空间和地址结构 在段页式系统中，为了实现从逻辑地址到物理地址的变换，系统中需要同时配置段表 和页表。段表的内容与分段系统略有不同，它不再是内存始址和段长，而是页表始址和页 表长度。图4-24示出了利用段表和页表进行从用户地址空间到物理（内存)空间的映射。 150  第四章存储器管理 操作系统 段表寄存器 页号状态存储块# 段表大小段表始址 0 1 。 2 1 段号状态页表大小页表始址 3 0 4 0 1 2 3 0 页号状态存储块# 1 段表 + ? 页表 主存 图4-24利用段表和页表实现地址映射\n\n2.地址变换过程 在段页式系统中，为了便于实现地址变换，须配置一个段表寄存器，其中存放段表始 址和段长TL。进行地址变换时，首先利用段号S，将它与段长TL进行比较。若S<TL， 表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中 得到该段的页表始址，并利用逻辑地址中的段内页号P来获得对应页的页表项位置，从中 读出该页所在的物理块号b，再利用块号b和页内地址来构成物理地址。图4-25示出了段 页式系统中的地址变换机构。 地址越界 段表寄存器 逻辑地址 段表始址 段表长度 段号S 页号P 页内地址W 段表 页表 01 0 1 2 3 b W 物理地址 图4-25段页式系统中的地址变换机构 在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内 存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的 物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正 从第二次访问所得的地址中取出指令或数据。 显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增 设一个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找 151  计算机操作系统 到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成物理地址；若 未找到匹配表项，则仍需第三次访问内存。由于它的基本原理与分页及分段的情况相似， 故在此不再赘述。\n\n1.为什么要配置层次式存储器？\n\n2.可采用哪几种方式将程序装入内存？它们分别适用于何种场合？\n\n3.何谓静态链接？静态链接时需要解决两个什么问题？\n\n4.何谓装入时动态链接？装入时动态链接方式有何优点？\n\n5.何谓运行时动态链接？运行时动态链接方式有何优点？\n\n6.在动态分区分配方式中，应如何将各空闲分区链接成空闲分区链？\n\n7.为什么要引入动态重定位？如何实现？\n\n8.什么是基于顺序搜索的动态分区分配算法？它可分为哪几种？\n\n9.在采用首次适应算法回收内存时，可能出现哪几种情况？应怎样处理这些情况？\n\n10.什么是基于索引搜索的动态分区分配算法？它可分为哪几种？\n\n11.令buddyk(x)为大小为2k、地址为x的块的伙伴系统地址，试写出buddyk(x)的通用 表达式。\n\n12.分区存储管理中常用哪些分配策略？比较它们的优缺点。\n\n13.为什么要引入对换？对换可分为哪几种类型？\n\n14.对文件区管理的目标和对对换空间管理的目标有何不同？\n\n15.为实现对换，系统应具备哪几方面的功能？\n\n16.在以进程为单位进行对换时，每次是否都将整个进程换出？为什么？\n\n17.基于离散分配时所用的基本单位不同，可将离散分配分为哪几种？\n\n18.什么是页面？什么是物理块？页面的大小应如何确定？\n\n19.什么是页表？页表的作用是什么？\n\n20.为实现分页存储管理，需要哪些硬件支持？\n\n21.在分页系统中是如何实现地址变换的？\n\n22.具有快表时是如何实现地址变换的？\n\n23.较详细地说明引入分段存储管理是为了满足用户哪几方面的需要。\n\n24.在具有快表的段页式存储管理方式中，如何实现地址变换？\n\n25.为什么说分段系统比分页系统更易于实现信息的共享和保护？\n\n26.分页和分段存储管理有何区别？\n\n27.试全面比较连续分配和离散分配方式。 152"
          }
        ]
      }
    ]
  }
]
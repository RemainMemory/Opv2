[
  {
    "一级标题": "第10章_多处理机操作系统",
    "二级内容": [
      {
        "二级标题": "10.1_多处理机系统的基本概念",
        "三级内容": [
          {
            "三级标题": "10.1.1 多处理机系统的引入 一← 进入70年代后，已采用多处理机的系统结构从提高运行速度方面来增强系统性能。实 际上，多处理机系统MPS就是采用并行技术，令多个单CPU同时运行，使总体的计算能 力比单CPU计算机系统的强大得多。归结起来，引I入多处理机系统的原因大致如下：",
            "正文": "1.CPU的时钟频率问题 在早期，人们首先是采用提高CPU时钟频率的方法提高计算速度。CPU的时钟频率 已从早期的每秒钟嘀嗒数十次，发展到现在的数兆赫兹(GHz)，这主要得益于芯片制造工艺 水平的提高。 但是，这种方法的收效是有极限的。因为CPU所运算的指令或数据及其结果都是以电 子信号的方式，通过传输介质送入或送出。因此，在一个时钟周期内，应至少保证信号在 传输介质中能完成一个往返的传输。换言之，CPU的时钟频率将受限于信号在介质上的传 输时间。电子信号在真空中的传输速度是30cm/ns，而在铜线或光纤中的传输速度大约是 20cm/ns。这意味着，对于1GHz的计算机，信号的路径长度不能超过200mm，对于100GHz 的计算机，则不能超过2mm；对于1000GHz(1THz)的计算机，则传输介质的长度必须在 100um以下。显然，这对缩小元器件体积的要求越来越高。 但是，随着元器件，尤其是CPU体积的缩小，散热又成了一个棘手的问题。CPU的 时钟频率越高，产生的热量也越多，散热问题越难解决。目前，在高端的Pentium系统中， CPU散热器的体积已经超过了其本身的体积。可见，目前的这种依靠提高CPU时钟频率来 提高计算机运算速度（系统性能）的方法，已经接近了极限。 307  计算机操作系统\n\n2.增加系统吞吐量 随着系统中处理机数目的增加，系统的处理能力也相应增强，显然，这可使系统在单 位时间内完成更多的工作，即增加系统吞吐量。当然，为了能使多个处理机协调地工作， 系统也必须为此付出一定的开销。因此，利用n台处理机运行时所获得的加速比，并不能 达到一台处理机时的n倍。\n\n3.节省投资 在达到相同处理能力的情况下，与n台独立的计算机相比，采用具有n个处理机的系 统，可以更节省费用。这是因为，此时的n个处理机可以做在同一个机箱中，使用同一个 电源和共享一部分资源，如外设、内存等。\n\n4.提高系统可靠性 在MPS中，通常都具有系统重构的功能，即当其中任何一个处理机发生故障时，系统 可以进行重构，然后继续运行。亦即可以立即将故障处理机上所处理的任务迁移到其它的 一个或多个处理机上继续处理，保证整个系统仍能正常运行，其影响仅仅表现为系统性能 上的少许降低。例如，对于一个含有10个CPU的系统，如果其中某一个CPU出现故障， 整个系统性能大约降低10%。"
          },
          {
            "三级标题": "10.1.2 多处理机系统的类型 此之间交换大量的信息。为此，必须将这些处理机加以互连。但是，不同的互连技术形成 了不同类型的系统及软件组织结构。其所构成的系统在性能、成本等各方面也存在着差异。 一般而言，可以从不同角度对多处理机系统的结构进行如下的分类：",
            "正文": "1.紧密耦合MPS和松弛耦合MPS 从多处理机之间耦合的紧密程度上，可把MIPS分为两类：\n\n（1）紧密耦合（TightlyCoupled)MPS。紧密耦合通常是通过高速总线或高速交叉开关来实现 多个处理器之间的互连的。系统中的所有资源和进程都由操作系统实施统一的控制和管理。这 类系统有两种实现方式：①多处理器共享主存储器系统和IO设备，每台处理器都可以对整 个存储器进行访问，访问时间一般需要10～50ns；②将多处理器与多个存储器分别相连，或 将主存储器划分为若干个能被独立访问的存储器模块，每个处理器对应一个存储器或存储器模 块，而且每个处理器只能访问其所对应的存储器或存储器模块，以便多个处理机能同时对主存 进行访问。在第二种互连方式中，处理器之间的访问采用消息通信方式，一条短消息可在10～ 50us之内发出，它较第一种互连方式慢，且软件实现复杂，但使用构件较为方便。\n\n(2）松散耦合(LooselyCoupled)MPS。在松散耦合MPS中，通常是通过通道或通信线路 来实现多台计算机之间的互连。每台计算机都有自己的存储器和IVO设备，并配置了OS 来管理本地资源和在本地运行的进程。因此，每一台计算机都能独立地工作，必要时可通 过通信线路与其它计算机交换信息，以及协调它们之间的工作。但在这种类型的系统中， 消息传递的时间一般需要10～50ms。\n\n2.对称多处理器系统和非对称多处理器系统 根据系统中所用处理器的相同与否，可将MPS分为如下两类： 308 \n\n(1）对称多处理器系统SMPS(SymmetricMultiprocessorSystem)。在系统中所包含的各 处理器单元，在功能和结构上都是相同的，当前的绝大多数MPS 都属于SMP系统。例如， IBM公司的SR/6000ModelF50，便是利用4片PowerPC处理器构成的。\n\n(2）非对称多处理器系统ASMPS（AsymmetricMultiprocessorSystem)。在系统中有多种类 型的处理单元，它们的功能和结构各不相同。系统中只有一个主处理器，有多个从处理器。"
          }
        ]
      },
      {
        "二级标题": "10.2_多处理机系统的结构",
        "三级内容": [
          {
            "三级标题": "10.2.1 UMA多处理机系统的结构 一一 一一一 所谓UMA(UniformMemoryAccess)，即统一内存访问（也称一致性内存访问)。在这种 结构的多处理机系统中，各处理器单元（CPU)在功能和结构上都是相同的，在处理上没有主 从之分（即属于SMP系统），每个处理机可以访问不同模块中的存储器单元，并且对于每个 存储器单元的读写速度是相同的。实际上，根据处理机与存储器模块的连接方式的不同， 可以具体分为以下三种结构：",
            "正文": "1.基于单总线的SMP结构 如图10-1(a)所示，在这种结构的系统中，把多个处理器与一个集中的存储器相连，所 有处理器都通过公用总线访问同一个系统的物理存储器，每个处理机可以访问不同存储器 模块中的单元，以及与其它处理机进行通信。这就意味着该系统只需要运行操作系统的一 个拷贝，因此，为单处理器系统编写的应用程序可以直接移植到这种系统中运行。实际上， 这种结构的SMP系统也被称为均匀存储器系统，即对于所有处理器来说，访问存储器中的 任何地址所需的时间都是一致的。 例如，当处理机需要读取某个存储器模块单元的内容（即一个存储器字）时，首先检查 总线的忙闲状态。如果空闲，CPU便将所要访问的存储器地址放到总线上，并插入若干控 制信号，然后等待存储器将所需的存储器字放到总线上；否则，如果总线状态为忙，则CPU 进行等待，直到总线空闲。 显然，这种结构的缺点在于可伸缩性有限。系统中所有CPU对存储器的访问，都需要 通过总线进行。多个CPU可能同时需要对总线进行访问，形成了对总线资源的争夺。随着 CPU数目的增加，由于总线资源的瓶颈效应，对此进行相关协调和管理的难度急剧增加， 从而限制了系统中CPU的数目。一般而言，在这种系统中，CPU的数目在4至20个之间。 对上述的问题，可以通过为每个CPU配置一个高速缓存的方法解决。如图10-1(b)所 309  计算机操作系统 示，这些高速缓存可以通过在CPU内部、处理机板、CPU附近等多种方式设置。这样，可 以把每个CPU常用的或者即将用到的数据存放在其本地的高速缓存中，可以很大程度地减 少该CPU对总线的访问频率，极大地减少总线上的数据流量，以支持更多的CPU。应该注 意的是，在这里，高速缓存的交换和存储是以32字节或64字节块为单位，而不是单个字 节。系统中高速缓存可以为所有CPU所共享，也可以为每一个CPU所独立拥有。 私有存储器 共享存储器 共享存储器 共享存储器 CPU CPU CPU CPU CPU M M M 总线 总线 高速缓存 (a)没有高速缓存 (b)有高速缓存 (c)有高速缓存和私有存储器 图10-1基于总线的SMP结构\n\n2.使用多层总线的SMP结构 对于单总线结构中存在的总线瓶颈问题的另一个解决方法，就是使用多层总线结构。 在这种结构中，系统中所有的CPU不仅共享一个高速缓存，还有一个本地私有的存储器， 如图10-1(c)所示。各CPU与本地的私有存储器、IO设备通过本地总线连接，系统再使用 系统总线将不同CPU的本地总线进行连接，并且将系统中的共享存储器连接在系统总线 上。系统总线一般在通信主板中实现，各CPU使用本地总线访问其本地私有存储器，而通 过系统总线访问共享存储器。 地把所运行程序的正文、字符串、常量和其它只读数据存放在其私有存储器中，仅将共享 变量存放在共享存储器中。这种结构可以很大程度地减少各CPU对系统总线的占用，因而 可以在相当程度上减少系统总线上的流量，使系统可以支持更多的CPU(16～32个)。 但是，这种方式提高了对程序编译器的要求，而为了尽可能减少使用总线的频率，就 需要对程序中的数据进行仔细的安排，显然这也增加了编程的难度。\n\n3.使用单级交叉开关的系统结构 在这种结构中，利用电话交换系统中使用交叉开关（crossbarswitch)的方法，如图10-2 所示，将系统中所有的CPU与存储器结点，通过交叉开关阵列相互连接。每个交叉开关均 之间因为要访问存储器模块所形成的对链路的争夺。而且，在任意两个结点(CPU与CPU) 之间也都能找到一个交叉开关，在它们之间建立专用连接通路，方便CPU之间的通信。 交叉开关的状态可根据程序的要求，动态地设置为“开”和“关”。例如图10-2(a)中 的三个小黑点，表示有三个交叉开关闭合，即允许(CPU，存储器)对(010,110)、（101,101)、 (110,010)同时连接。 310  第十章 多处理机操作系统 交叉点开关打开 000 001 010 011 (b) 100 101 交叉点开关关闭 关闭的交叉点开关 打开的交叉点开关 (a) (c) 图10-2使用交叉开关的UMA多处理机系统 使用交叉开关的UMA多处理机系统具有如下特征：\n\n（1）结点之间的连接：交叉开关一般是构成一个N×N的阵列，但在每一行和每一列 中，都同时只能有一个交叉点开关处于“开”状态，从而它同时只能接通N对结点。\n\n(2）CPU结点与存储器之间的连接：每个存储器模块同时只允许一个CPU结点访问， 故每一列只能接通一个交叉点开关，但是为了支持并行存储访问，每一行同时可以接通多 个交叉开关。\n\n(3）交叉开关的成本为N²，N为端口数，限制了它在大规模系统中的应用，如1000个 CPU与1000个存储器模块连接，就需要1百万个交叉点，这在现实中是不可行的。一般 只适合于8～16个处理器的中等规模系统。\n\n4.使用多级交换网络的系统结构 图10-3(a)是一个最简单的2×2交叉开关，它有两个输入和两个输出。送入任一输入的 CPU 3级 存储器 000 000 1A 2A 001 001 010 010 B 2B 3B 011 011 100 100 1C 2C 3C 101 101 110 110 111 (a)一个2×2的交换机 (b)使用多级交换开关的结构 图10-3使用多级交换网络的SMP结构示意图 311  计算机操作系统 信息可以交换到任一输出线上。可以将这样的多级小交换开关分级连接起来，形成多级交 叉开关网络，如图10-3(b)所示，图中的1A、2A、“、1B、“、3C等都是一个交叉开关级， 在相邻级别的交叉开关之间设置固定的物理连接。处理机和存储器模块分别位于网络的两侧， 每台处理机通过网络访问存储器模块，而且所有处理机的访问方式都是一样的，机会均等。 在这种结构中，由于对每个CPU都提供了多条到每个存储器模块的路径，因而减少了 阻塞概率，很好地分散了流量，提高了访问速度。其缺点在于，硬件结构昂贵，且系统中 处理机数目也不适合过多，一般在100个以下。 如前所述，以上四种SMP体系结构的多处理机系统具有一个共同的特征，就是共享， 每一个处理机对系统中所有资源(内存、IO等)都是共享的。也正是由于这种特征，决定了 这种结构的扩展能力非常有限：每一个共享的环节都可能造成处理机扩展时的瓶颈：对处 理机而言，最受限制的是内存，每个CPU必须通过公用的总线（或连接路径)，访问相同（或 彼此)的内存资源。随着CPU数量的增加，公用总线(或连接路径）的流量急剧增加，形成超 载，致使内存访问冲突将迅速增加，并成为制约提高系统性能的瓶颈，造成CPU资源的浪 费，很大程度地降低了CPU性能的有效性。 由于SMP在这种扩展能力上的限制，人们开始探究如何进行有效的扩展，才能构建大 型系统的技术，NUMA就是这种探究的成果之一。利用NUMA技术，可以把几十个CPU（甚 至上百个CPU)组合在一个服务器内。"
          },
          {
            "三级标题": "10.2.2 NUMA多处理机系统结构",
            "正文": "1.NUMA结构和特点 所谓NUMA(Nonuniform-Memory-Access)，即非统一内存访问（也称非一致存储访问)。在 这种结构的多处理机系统中，其访问时间随存储字的位置不同而变化，系统中的公共存储期 和分布在所有处理机的本地存储器共同构成了系统的全局地址空间，可被所有的处理机访问。 如图10-4所示，NUMA拥有多个处理机模块（也称为节点），各节点之间通过一条公用总 节点0 节点256 cpul cpu4 cpul cpu4 局部总线 局部总线 高速缓存 高速缓存 目录 群内共享 目录 群内共享 存储器 ！存储器 互连网络或公用总线 图10-4NUMA结构的多处理机系统 312  第十章多处理机操作系统 线或互连模块进行连接和信息交互。每个节点又可以由多个处理机(CPU)组成，如四个奔腾微 处理器，它们分别拥有各自独立的本地存储器、IO槽口等，并通过一条局部总线与一个单独 的主板上的共享存储器（也称群内共享存储器）连接。这样一个系统一般可以包含16到256个 CPU。由此可见，因为通过互连网络会产生附加延迟，处理机访问本地存储器是最快的，但 访问属于另一台处理机的远程存储器则比较慢。所有机器都有同等访问公共存储器（也称全局 存储器）的权利，但是访问群内存储器的时间要比访问公共存储器短。对于机群间存储器的访 问权，也可用不同的方法描述。伊得诺依大学研制的Cedar多处理机就使用这种结构。 NUMA结构的特点是：所有共享存储器在物理上是分布式的，在逻辑上是连续的，所 有这些存储器的集合就是全局地址空间，系统中的每一个CPU都可以访问整个系统的内 存，但访问时所使用的指令却不同；因此，在NUMA中，存储器一般分为三层：①）本地 存储器；②群内共享存储器：③全局共享存储器或其它节点存储器。显然，每一个CPU 访问本地存储器的速度远远高于访问全局共享存储器或远程访问其它节点存储器（远地内 存）的速度。 对一个运行在NUMA多处理机系统中的应用程序而言，系统提供了一个地址连续的、 完整的内存空间，但当一个处理器在特定内存地址寻找数据的时候，可能需要访问三层（级） 存储器：首先察看CPU的本地存储器，其次是本节点的共享存储器，最后是其它节点的“远 程内存”（或全局共享存储器）。可见，为了更好地发挥系统性能，开发应用程序时，应注 意尽量减少不同节点之间的信息交互。 对于NUMA多处理机结构，为了减少CPU对远程内存的访问，还可以通过为每个CPU 再配备各自的高速缓存的方法实现，这样的结构称为CC-NUMA。与此对应的，将每个CPU 没有配备各自的高速缓存的结构称为NC-NUMA。\n\n2.CC-NUMA构造方法 目前，对于构造大型的CC-NUMA多处理机系统，最常用的方法是采用基于目录的多 处理机。其基本思想是：对于系统中每一个CPU所拥有的若干高速缓存单元，都以一定数 量的单元为一组，构成一个高速缓存块，为每个CPU配置一张高速缓存块目录表（下简称 目录表)，对每一个高速缓存块的位置和状态进行记录和维护。每个CPU的每条访问存储 器单元的指令都必须首先查询这张表，从中判断该存储器单元是否在目录表中，即其内容 读取高速缓存内容、变换高速缓存块节点，修改目录表等。下面将用一个简单的例子加以 具体的阐述。 例如，在一个拥有256个节点的NUMA多处理机系统中，每个节点可以包含若干个 网络连接，其中节点1包含0～16MB，节点2包含16～32MB，“，以此类推，系统整 个存储器空间包含了16M×256=224×2°=232个字节。其中，由于一个节点中有四个CPU 共享16MB的本地存储器，因此该存储器被划分为四个部分，分别提供给四个CPU作为 其本地存储器，即每个CPU拥有4MB空间(22)，其中CPU1包含0～4MB，CPU2包含4~ 8MB，·….…….，以此类推。 考虑到每一个CPU都拥有一张目录表，其中的每一个表项应记录一个本地高速缓存块 地址，该高速缓存块中的每一个高速缓存单元内容，是本地某个存储器单元内容的拷贝。 313  计算机操作系统 因此，对于32位机而言，比较合适的方法是采用16位的表项长度，将存储器空间划分为若 干个长度为64字节(222/216=2°)的存储器单元组，对应地，也将高速缓存中64个字节为一组 为使描述简单起见，下面只考虑每个节点中只有一个CPU的情况，如图10-5(a)所示。 当CPU20（即20号节点的CPU)发出一条远程存储器单元访问指令后，由操作系统（中的 MMU)将地址翻译成物理地址，并拆分为三个部分，如图10-5(b)所示，节点号36，第4块， 块内偏移量8，即访问的存储器不是20号节点的，而是36号节点。然后，MMU将请求消 息通过互连网络发送给节点36，并询问第4块是否已在高速缓存中，如果是，则请求高速 缓存的地址。 36号节点接收到请求后，通过硬件检索其本地目录表的第4项，如图10-5（c）所示，该 项内容为空，即要访问的存储器块内容没有进入高速缓存。通过硬件将36号节点本地RAM 中的第4块内容传送到20号节点，并将本地目录中第4项内容进行更新，指向20节点， 表示该存储块内容进入了20号节点的高速缓存。 节点0 节点1 节点256 CPU CPU CPU 存储器 存储器 存储器 目录 目录 目 局部总线 局部总线 局部总线 互连网络 (a)基于目录256节点的多处理机 218-1 ： 8 18 6 0 节点 块 偏移量 0 1 82 0 0 (b)32位存储器地址分为三个域 (c)位于36字节的目录 图10-5-CC-NUMA构造方法 现在，再考虑第二种情况。CPU20发出的请求是节点36的第2项，如图10-5（c）所示， 36号节点接收到该请求后，发现该项内容为82，即要访问的存储器块内容已经进入82号 节点的高速缓存，于是更改本地目录中的第2项内容，将其指向20号节点，然后发送一条 消息到82号节点。82号节点接收到消息后，从其高速缓存第2块中取出内容发送回20号 节点，并同时修改本地目录中第2项内容，将其指向20号节点，并将相应高速缓存块中的 内容作废。20号节点接收到82号节点返回的内容后，存入本地高速缓存的第2块，修改 本地目录的第2项，将其指向本地高速缓存第2块。 从上述过程可以看出，在这种NUMA结构的多处理机系统中，仍然需要通过大量的消 息传递的方法实现存储器共享。同时，由于每个存储块只能进入一个节点的高速缓存，因 而限制了对存储器访问速度的提高。 因此，NUMA技术的主要问题是：远程内存访问由于访问远地内存的延时远远超过本 地内存，因此当CPU数量增加时，系统性能无法线性增加。 314  第十章多处理机操作系统"
          }
        ]
      },
      {
        "二级标题": "10.3_多处理机操作系统的特征与分类",
        "三级内容": [
          {
            "三级标题": "10.3.1 多处理机操作系统的特征 一 多处理机操作系统是在单机多道程序系统的基础上发展起来的，它们之间有许多相似 之处，但也存在着较大的差异。归纳起来，多处理机操作系统具有以下几方面的新特征：",
            "正文": "1.并行性 单机多道程序系统的主要目标是，为用户建立多个虚拟处理机以及模拟多处理机环境， 使程序能并发执行，从而改善资源利用率并提高系统的吞吐量。而在多处理机系统中，由 于存在着多个实处理机，已经可使多个进程并行执行，因此，多处理机操作系统的主要目 标应是进一步增强程序执行的并行性程度，以获得更高的系统吞吐量及提高系统的运算速 度。实际上，在多处理机系统中，每个实处理机仍然可以通过多道程序技术，虚拟为若干 个虚拟处理机，使多个进程在一个实处理机上并发执行。因此，在多处理机系统中，多个 进程之间存在着并行执行和并发执行两种关系。 对于开拓硬件操作的并行性及程序执行的并行性，始终是多处理机系统的中心问题。 前者主要依赖于系统结构的改进，后者则是操作系统的主要目标和任务。为了描述任务的 并行性，控制它们的并行执行，还应该配置相应的并行程序语言，以便在一个任务开始时， 能够派生出与之并行执行的新任务。对于程序执行并行性的开拓，必然导致处理机管理及 存储器管理等功能在实现上的复杂化。\n\n2.分布性 在单处理机系统中，所有的任务都是在同一台处理机上执行的，所有的文件和资源也 都处于操作系统的统一管理之下。然而对于多处理机系统而言，无论其结构如何，在任务、 资源和对它们的控制等方面，都呈现出一定的分布性。这种情况，在松散耦合系统中表现 尤其明显：\n\n（2）资源的分布：各处理机都可能拥有属于自己的本地资源，包括存储器、IO设备等， 对这些资源的使用可以是私有方式，也可以是提供给其它处理机的共享方式；\n\n（3）控制的分布，在系统的每个处理单元上，都可能配置有自己的操作系统，用于控 制本地进程的运行和管理本地资源，以及协调各处理机之间的通信和资源共享。\n\n3.机间的通信和同步性 在多处理机系统中，不仅在同一处理机上并发执行的诸进程之间，由于资源共享和相 互合作的需要，须实现同步和通信，而且在不同处理机上运行的不同进程之间，也需要进 行同步和通信，除了它们之间也需要资源共享和相互合作外，这对于提高程序执行的并行 性、改善系统的性能至关重要。但在多处理机系统中，不同处理机之间的同步和通信，其 实现机制远比单处理机系统要复杂的多，因而成为多处理机操作系统中最重要的问题之一。 315  计算机操作系统\n\n4.可重构性 为提高系统的可靠性，在多处理机系统中，应使操作系统具有这样的能力：当系统中 某个处理机或存储模块等资源发生故障时，系统能够自动切除故障资源，换上备份资源， 并对系统进行重构，保证其能继续工作。如果在故障的处理机上有一个进程正在执行，系 统应能将其安全地转移到其它正常的处理机上继续运行，同时对故障处理机上处于其它状 态的进程，也予以安全的转移。"
          },
          {
            "三级标题": "10.3.2 多处理机操作系统的功能 从资源管理观点来看，虽然多处理机操作系统也具有单机操作系统所具有的各种功能， 即进程管理、存储器管理、设备管理、文件管理和作业管理五大功能，但相比之下，在以 下几方面又具有明显的不同：",
            "正文": "1.进程管理 对于多处理机系统中的进程管理，主要体现在进程同步和进程通信几个方面： 1）进程同步 在单处理机多道程序系统中，由于各进程只能交替执行，不会发生两个进程在同一时 刻同时访问系统中同一个共享资源的情况。然而，在多处理机环境下，由于多个进程在不 同的处理机上是并行执行的，因而可能出现多个进程对于某个共享资源的同时访问。可见， 在多处理机操作系统中，不仅需要解决程序并发执行时引发的同步问题，而且还需要解决 在多个不同的处理机程序并行执行时所引发的同步问题。因此，对于这两类进程同步问题 的解决机制，除了通常的锁、信号量和管程外，还应具有新的同步机制和互斥算法。 2）进程通信 在单机环境中，所有进程都采用共享同一存储器方式，驻留在同一台机器中。这样， 进程间通信的主要方式是“共享存储器”方式和直接通信方式。但在多处理机环境中，相 互合作的进程可能运行在不同的处理机上，它们之间的通信必然涉及到处理机间的通信， 特别是在松散耦合型的多处理机系统中，进程甚至在不同的机器上，其间的通信还需要较 长的通信信道，甚至要经过网络。因此，在多处理机系统中，进程通信的实现广泛地采用 了间接通信方式。 3）进程调度 在单机环境中，进程调度只是简单地按照一定的算法，从就绪队列中选择一个进程， 为之分配处理机的一个时间片，使之执行一段时间。为平衡IVO负载，在调度时适当地进 行IO任务和计算任务的搭配，以提高系统的资源利用率。但在多处理机系统中，发挥多 处理机最大效能的关键，在于提高程序执行的并行性。因此，在进程调度时，主要应考虑 到如何实现负载的平衡。在调度任务以为其分配处理机时，一方面必须了解每台处理机的 能力，以便把适合的任务分配给它，另一方面，也要确切地了解作业中诸任务之间的关系， 即哪些任务间必须顺序执行，哪些任务可以并行执行。\n\n2.存储器管理 在多处理机环境下，通常每个处理机都有属于自己局部的(本地)存储器，也有可供多 个处理机所共享的(系统)存储器。每个处理机在访问本地存储器模块时，与访问系统存储 316  第十章多处理机操作系统 器或其它处理机的局部存储器模块（统称远地存储器）时相比，所花费的时间也可能是不同 的。因此，在多处理机系统中，存储器系统的结构十分复杂，致使对存储器系统的管理也 还应增强和增加下面的功能和机制：\n\n（1）地址变换机构。该机构不仅用于将虚拟地址转换成实际物理地址，还应能确定所 访问的是本地存储器还是远地存储器。事实上，在目前很多支持多处理机的操作系统中， 对整个存储器系统已经采用连续的地址方式进行描述，即一个处理机无需专门去识别所要 访问的存储器模块的具体位置。\n\n(2）访问冲突仲裁机构。当多个处理机上的进程同时竞争访问某个存储器模块时，该 机构能够按照一定的规则，决定哪一个处理机上的进程可立即访问，哪个或哪些处理机上 的进程应等待。\n\n(3）数据一致性机制。当共享主存中的某个数据在多个处理机的局部(本地)存储器中出 现时，操作系统应保证这些数据的一致性。\n\n3.文件管理 在单处理机系统中，通常只有一个文件系统，所有的文件都存放在磁盘上，采用集中 统一管理方式，也称为集中式文件系统。而在多处理机系统中，则可能采用以下三种文件 系统管理方式：\n\n(1）集中式。所有处理机上的用户文件都集中存放在某一个处理机的文件系统中，由 该处理机的操作系统进行统一管理。\n\n(2）分散式。各处理机上都可配置和管理自己的文件系统，但整个系统没有将它们有 效地组织起来，因而无法实现处理机之间的文件共享。\n\n(3）分布式。系统中的所有文件可以分布在不同的处理机上，但在逻辑上组成一个整 体，每台处理机上的用户无需了解文件的具体物理位置，即可实现对它们的存取。在这样 的文件系统中，解决文件存取的速度和对文件的保护问题，具有很重要的意义。\n\n4.系统重构 在单处理机系统中，一旦处理机发生故障，将引发整个系统的崩溃。但在多处理机系 统中，尤其是在对称多处理机系统中，由于各处理机的结构和功能相同，为了提高系统的 可靠性，应使操作系统具有重构能力，即当系统中某个处理机或存储块等资源发生故障时， 系统能够自动切除故障资源并换上备份资源，使之继续工作。如果没有备份资源，则重构 系统使之降级运行。如果在故障的处理机上有进程函待执行，操作系统应能安全地把它迁 移到其它处理机上继续运行，对处于故障处的其它可利用资源同样也予以安全转移。"
          },
          {
            "三级标题": "10.3.3 多处理机操作系统的类型 一一一一 在多处理机系统中，目前所采用的操作系统有以下三种基本类型：",
            "正文": "1.主从式（master-slave) 在这种类型的操作系统中，有一台特定的处理机被称为主处理机(MasterProcessor)，其 它处理机则称为从处理机。操作系统始终运行在主处理机上，负责保持和记录系统中所有 处理机的属性、状态等信息，而将其它从处理机视做为可调度和分配的资源，负责为它们 317  计算机操作系统 分配任务。从处理机不具有调度功能，只能运行主处理机分配给它的任务。 其工作流程是：由从处理机向主处理机提交任务申请，该请求被捕获后送至主处理机， 而后等待主处理机发回应答；主处理机收到请求后中断当前任务，对该请求进行识别和判 断，并转入执行相应的处理程序，然后将适合的任务分配给发出请求的从处理机。例如， CDCCyber-170就是典型的主从式多处理机操作系统，它驻留在一个外围处理机Po上运行， 其余所有处理机包括中心处理机都从属于Po，Po专门用于执行操作系统功能，处理用户程 序(运行在从处理机上)发来的请求。另外一个例子就是DECSystem10，该系统有两台处理 机，一台为主处理机，另一台为从处理机。 主从式操作系统具有如下优缺点：\n\n（1）易于实现。一方面其设计可在传统的单机多道程序系统上进行适当的扩充；另一方面， 由于操作系统程序仅被一台主处理机使用，因此除了一些公用例程外，不需要将整个管理程序\n\n(2）资源利用率低。由于从处理机的所有任务都是由主处理机分配的，当从处理机数 量较多时，或者从处理机执行的是大量的短任务时，在主处理机上会出现较长的请求任务 队列，形成了瓶颈，使从处理机长时间处于等待状态，导致从处理机以及其所配置的IV/O 设备利用率降低。因此，一方面，系统中从处理机的数量不宜设置过多，另一方面主处理 机在分配任务时，不宜将任务划分得过小，以避免从处理机频繁地发出请求。\n\n（3）安全性较差。由于系统中只有一台主处理机，并且由其负责运行操作系统，对整 尽管主一从式操作系统的资源利用率低下、安全性较差，但因其易于实现，所以在早 期的多处理机系统中还主要采用这样的形式，直至目前，仍有不少的多处理机系统采用它。 一般用于工作负载不是太重、从处理机数量不是太多、从处理机性能远低于主处理机的非 对称多处理机系统中。\n\n2.独立监督式（separatesupervisorSystem） 独立监督式，也称为独立管理程序系统，它与主从式不同。在这种系统中，每个处理 机上都有自己的管理程序（操作系统内核)，并拥有各自的专用资源，如IO设备和文件系统。 每一个处理机上所配置的操作系统也具有与单机操作系统类似的功能，以服务自身的需要， 及管理自己的资源和为进程分配任务。采用独立监督式操作系统的多处理机系统有IBM 370/158等。独立监督式操作系统具有如下的优缺点：\n\n（1）自主性强。每个处理机都拥有独立的、完善的硬、软件资源，可根据自身以及分 配给它的任务的需要，执行各种管理功能，从而使系统具有较强的独立性和自主性。\n\n(2）可靠性高。每个处理机相对独立，因此一台处理机的故障不会引起整个系统崩溃， 使系统具有较高的可靠性。但是，由于缺乏一个统一的管理和调度机制，一旦出现故障， 要想进行补救或重新执行故障机未完成的工作，就显得非常困难。\n\n（3）实现复杂。由于存在着通信和资源共享的需要，各处理机之间必然有交互作用， 即多个处理机都可能在执行管理程序，因此管理程序的代码必须是可重入的，或者为每个 处理机提供一个专用的管理程序副本。此外，虽然每个处理机都有其专用的管理程序，对 公用表格的访问冲突较少，阻塞情况也相应减少，系统的效率较主从式有所提高，但仍然 318  会因为都要对一些公用表格进行访问而发生冲突，因此系统中还是需要设置冲突仲裁机构。\n\n（4）存储空间开销大。一般地，这类操作系统适用于松散耦合型多处理机系统，由于 每个处理机均有一个本地（局部)存储器，用来存放管理程序副本，即每台处理机中都驻留了 操作系统内核，占用了大量的存储空间，造成较多的存储余，致使存储空间利用率不高。\n\n（5）处理机负载不平衡。由于不能像主一从式系统中那样，由一个主处理机统一负责 整个系统的管理和调度，因而要实现处理机负载平衡非常困难。\n\n3.浮动监督式（floatingsupervisorControlMode) 浮动监督式，也称为浮动管理程序控制方式，这是最复杂的，但也是最有效、最灵活 的一种多处理机操作系统方式，常用于紧密耦合式的对称多处理机系统中。在这种方式实 现的系统中，所有的处理机组成一个处理机池，每台处理机都可对整个系统中的任何一台 IVO设备进行控制，以及对任何一个存储器模块进行访问，这些处理机由操作系统统一进行 管理，在某段时间内可以指定任何一台（或多台）处理机作为系统的控制处理机，即所谓“主” 处理机（或组），由它(或它们)运行操作系统程序，负责全面管理功能，但根据需要，“主” 处理机是可以浮动的，即从一台处理机切换到另一台处理机。采用这种操作系统方式的多 处理机系统有IBM3081上运行的MVS，VM以及C·mmp上运行的Hydra等。 浮动监督式操作系统具有如下的优缺点：\n\n（1）高灵活性。由于对于系统内所有的处理机采用的是处理机池管理方式，其中每一 台处理机都可用于控制任一台I/O设备和访问任一存储块，因此大多数任务可在任何一台 处理机上运行，使系统的灵活性相当强。\n\n(2）高可靠性。在上述三种操作系统中，浮动监督式操作系统具有最好的可靠性。因 为，系统中任何一台(从)处理机的失效，不过是处理机池中减少了一台可供分配的处理机 而已；而如果是“主”处理机失效，也只需将操作系统浮动（切换）到另一台处理机上运行， 从而保证系统仍能继续正常运行下去。\n\n(3）负责均衡。在这样的系统中，一方面由于大多数任务可以在任何一台处理机上运 行，另一方面也因为在系统中设置了一台（或多台）“主”处理机，对整个系统的资源和调 度进行了统一的管理，因此可以根据各处理机的忙闲情况，将任务均匀分配到各处理机上 执行，尤其是可以将一些非专门的操作（如IO中断)，分配给那些在特定时段内最不忙的处 理机去执行，使系统的负载达到较好的平衡。\n\n(4）实现复杂。一方面，由于对存储器模块和系统表格访问冲突的不可避免，需要配 置功能较强的冲突仲裁机构，包括硬件和软件两方面。例如，多个处理机同时访问同一存 储器模块时，可采用硬件解决；而对系统表格的冲突访问，则可采用静态或动态优先级策略； “主”处理机，即可以同时执行同一个管理服务子程序，因此，要求管理程序具有可重入性。"
          }
        ]
      },
      {
        "二级标题": "10.4_进程同步",
        "三级内容": [
          {
            "三级标题": "10.4.1 集中式与分布式同步方式",
            "正文": "1.中心同步实体 为实现进程之间的同步，系统中必须有相应的同步实体(SynchronizingEntity)，如硬件 锁、信号量以及进程等。如果该同步实体满足下述两个条件，则称之为中心同步实体：\n\n（1）具有唯一的名字，并且为彼此必须同步的所有进程所知道。 立即选择一个新的中心同步实体投入运行。\n\n2.集中式同步机构 基于中心同步实体所构成的所有同步机构被称为集中式同步机构。相应的，其它同步 机构则称为非集中式同步机构。在单处理机系统中，为了同步多个进程对共享数据的访问， 内核采用了一些同步机制，如硬件锁、信号量等。而对于多处理机系统而言，同样是为实 并发进程进行同步，还需对不同处理器上的进程进行同步，以保证多处理机系统能有条不 紊地运行。为此，在多处理机系统中，又增加了一些如自旋锁、RCU锁、时间邮戳、事件 计数以及中心进程等多种同步机制。\n\n3.集中式与分布式同步算法 在多处理机系统中，为实现进程同步，往往还需要有相应的同步算法支持同步机构， 一般分为以下两种：\n\n（1）集中式同步算法。集中式同步算法具有两个特征：①对于多个进程需要同时访问 共享资源或进行通信时，仅由中心控制结点做出判定，选择一个进程执行；②判定所需要 的全部信息都集中在中心控制结点。集中式同步算法的缺点在于：①可靠性差，由于中心 控制结点的故障，会对系统造成灾难性的影响，对此，有的系统充许中心控制结点进行浮 大量的资源共享和进程通信都是通过中心控制结点进行管理的，很容易使中心控制结点成 为整个系统的瓶颈，严重影响到系统的响应速度和吞吐量。\n\n(2）分布式同步算法。一个完全分布式同步算法具有以下特征：①所有结点具有相同 的信息；②所有结点仅基于本地信息做出判断：③为了做出最后的判定，所有的结点担 负相同的职责；④为了做出最后的判定，所有的结点要付出同样的工作量；5通常一个 结点发生故障，不会导致整个系统的崩溃。事实上，完全分布式算法的应用很少，大多数 同步算法都无法同时满足上述五点要求。\n\n4.中心进程方式 该方式是在系统中设置一个中心进程(或称为协调进程)，该进程保存了所有用户的存 取权限、冲突图(conflict graph)等信息。每一个要求访问共享资源的进程，都先向中心进程 发送一条请求消息，中心进程收到该请求后，便去查看冲突图，如果该请求不会引起死锁， 320  第十章多处理机操作系统 便将该请求插入请求队列，否则退回该请求（rollback)。当轮到该请求使用共享资源时，中 心进程便向请求进程发送一条回答消息，然后请求进程即可进入自己的临界区，访问共享 资源。请求进程在退出临界区后，还需要向中心进程发送一条释放资源的消息，中心进程 接收到该消息后，又可向下一个请求进程发送回答消息，允许它进入其临界区。在这种同 步方式中，任何一个进程要进入其临界区，都需要请求、回答、释放三个消息。为了提高 系统的可靠性，中心进程应可以浮动。 在单处理机系统和共享存储器的多处理机系统中，基本上都是采用集中式同步方式。 而在分布式系统中，则都是采用分布式同步方式。对于松散耦合式多处理机系统（包括计算 机网络），则一部分采用集中式，另一部分采用分布式。本节只对几种常用的同步机构和算 法进行介绍。"
          },
          {
            "三级标题": "10.4.2 自旋锁（spinlock）",
            "正文": "1.自旋锁的引入 如前所述，在单CPU系统中，CPU在执行读一修改一写原语操作时，是具有原子性 的，即在执行这些操作时不会被中断。保证原子性的基本方法是，在执行原语之前关中断， 完成后再开中断。但是，在对称多处理机系统中，CPU在执行读一修改一写原语时，已不 能再保证其操作的原子性。因为CPU所执行的读一修改一写原语操作通常都包含了若干条 享，它们是通过竞争来获取总线的。如果某CPU在执行原语的过程中由其它CPU争得了 总线，就可能会导致该CPU与其它CPU对同一存储单元读一写操作的交叉，造成混乱。 因此，在多处理机系统中，还必须引入对总线实现互斥的机制。于是，自旋锁机制也就应运 而生，并已大量应用于对总线资源的竞争。当然，自旋锁机制并不局限于对总线资源的竞争。\n\n2.实现对总线互斥访问的方法 利用自旋锁实现对总线互斥访问的方法是：在总线上设置一个自旋锁，该锁最多只能 被一个内核进程持有。当一个内核进程需要使用总线，对某个存储单元进行读写访问时， 先请求自旋锁，以获得对总线的使用权。如果该锁被占用，那么这个进程就会一直进行“旋 转”，循环测试锁的状态，直到自旋锁重新可用。如果锁未被占用，请求该锁的内核进程便 能立刻得到它，并且继续执行，直到完成对指定存储单元的读写操作后，释放该锁。可见， 自旋锁可以在任何时刻防止多个内核进程同时进入临界区，因此可有效地避免多处理机上 并发运行的内核进程对总线资源的竞争。\n\n3.自旋锁与信号量的主要差别 自旋锁与信号量的主要差别在于：自旋锁可避免调用进程阻塞。由于自旋锁使用者一 般保持锁时间非常短，调用进程用“旋转”来取代进程切换。而我们知道进程切换需要花 费一定开销，并且会使高速缓存失效，直接影响系统的性能，因此将自旋锁应用于对总线 资源的竞争，其效率远高于信号量机制，且在多处理器环境中非常方便。 显然，用自旋锁所保护的临界区一般都应比较短，否则，发出请求的多个CPU在锁被 占用时，就会因为都只是对锁进行循环测试，即忙等，浪费过多的CPU资源。 一般而言，如果对于被保护的共享资源仅在进程的上下文访问，或有共享设备，或调 321  计算机操作系统 用进程所保护的临界区较大时，应使用信号量进行保护。但是如果被保护的共享资源需要 中断上下文访问，或调用进程所保护的临界区非常小，即对共享资源的访问时间非常短的 情况下，就应使用自旋锁。自旋锁保持期间是不可抢占的，而信号量和读写信号量保持期 间是可以被抢占的。自旋锁只有在内核可抢占或SMP的情况下才真正需要，在单CPU且 不可抢占的内核下，为防止中断处理中的并发操作，可简单采用关闭中断的方式，不需要 自旋锁，此时自旋锁的所有操作都是空操作。\n\n4.自旋锁的类型 使用自旋锁的基本形式为： spin_lock(&lock); /*临界区代码；*/ .·... spin_unlock(&lock); 常用的自旋锁有三种类型：普通自旋锁、读写自旋锁和大读者自旋锁。\n\n（1）普通自旋锁：若是锁可用，则将自旋锁变量置为0，否则为1。该类自旋锁的使用 不会影响当前处理机的中断状态，一般在临界区的代码在禁止中断情况下使用，或者不能 被中断处理程序所执行。\n\n(2）读写自旋锁：允许多个读者同时以只读的方式访问相同的共享数据结构，但是当一个 写者正在更新这个数据结构时，不允许其它读者或写者访问。该类自旋锁较普通自旋锁充许更 数和一个解锁标记。一般而言，在写者等待的情况下，新进的读者较写者更容易抢占该锁。\n\n（3）大读者自旋锁：获取读锁时只需要对本地读锁进行加锁，开销很小：获取写锁时 则必须锁住所有CPU上的读锁，代价较高。"
          },
          {
            "三级标题": "10.4.3 读一拷贝一修改锁和二进制指数补偿算法",
            "正文": "1.读一拷贝一修改锁（RCU）的引I入 不论是第二章中的读写问题，还是前面所介绍的读写自旋锁，都是允许多个进程同时 读，但只要有一个写进程在写，便禁止所有读进程去读，使读者进入阻塞状态。如果写的 时间非常长，将严重影响到多个读进程的工作。是否能改善这一情况呢？即使有写进程在 写，读进程仍可以去读，不会引起读进程的阻塞。回答是肯定的，其解决方法是改变写进 程对文件(共享数据结构)进行修改（写）的方式。此即，当某写进程要往某文件中写入数据时， 它先读该文件，将文件的内容拷贝到一个副本上，以后只对副本上的内容进行修改。修改 完成后，在适当时侯再将修改完后的文件全部写回去。\n\n2.RCU（Read-Copy-Update)锁 RCU锁用来解决读者一写者问题。对于被RCU保护的共享文件(数据结构)，无论读者 和写者，都是以读的方式对其进行访问的，对于读者而言，不需要获得任何锁就可以访问 它，对于写者而言，在访问它时，先制作该文件的一个副本，只对副本上的内容进行修改， 然后使用一个回调（callback)机制，即向系统中一个称为垃圾收集器的机构注册一个回调函 数。最后，在适当的时机，由垃圾收集器调用写者注册的回调函数，把指向原来数据的指 针重新指向新的被修改的数据，完成最后的数据释放或修改操作。 322 \n\n3.写回时机 在RCU锁机构中，如何确定将修改后的内容写回的时机？显然，最好是在所有读者都 已完成自已的读任务后再将修改后的文件写回。为此，每一个读者完成对共享文件的操作 后，都必须向写者提供一个信号，表示它不再使用该数据结构。当所有的读者都已经发送 信号之时，便是所有引I用该共享文件的CPU都已退出对该共享数据的操作之时，也就是写 者可以将修改后的文件写回之时。对于写者而言，从对副本修改完成后，到执行真正的写 修改，中间有一段延迟时间，称为写延迟期（graceperiod)。\n\n4.RCU锁的优点 RCU实际上是一种改进的读写自旋锁。它的主要优点表现为如下两方面：\n\n（1）读者不会被阻塞。读者在访问被RCU保护的共享数据时不会被阻塞。这一方面极 大地提高了读进程的运行效率，另一方面也使读者所在的CPU不会发生上下文切换，减少 了处理机的开销。 个写者同时访问被保护的数据，无需为共享数据设置同步机构，因而读者没有什么同步开 销，也不需要考虑死锁等问题。但是写者的同步开销却比较大，需要复制被修改的数据结 构，延迟数据结构的释放，还必须使用某种锁机制，与其它写者的修改操作同步并行。 操作较多，而写操作很少，用RCU的确是利大于弊；反之，如果写比较多，对读者的性能 提高可能不足以弥补给写者带来的损失，此时还是应当采用读写自旋锁。"
          },
          {
            "三级标题": "10.4.4 二进制指数补偿算法和待锁CPU等待队列机构 一",
            "正文": "1.二进制指数补偿算法 多个CPU在对共享数据结构互斥访问时，如果该数据结构已被占用，就需要不断地对 锁进行测试，造成总线流量的增大。二进制指数补偿算法的基本思想是：为每一个CPU对 锁进行测试的TSL指令设置一个指令延迟执行时间，使该指令的下次执行是在该延迟执行 时间设定的时间后进行，其延迟时间是按照一个TSL指令执行周期的二进制指数方式增加。 例如当一个CPU发出TSL指令对锁进行第一次测试，发现锁不空闲时，便推迟第二次测 试指令的执行时间，等到2个指令执行周期后，如果第二次测试仍未成功，则将第三次测 试指令的执行时间推迟到22个指令执行周期后，·…，如果第n-1次测试仍未成功，则 将第n次的测试推迟到2-个指令执行周期后，直到一个设定的最大值；当锁释放时，可 能首先由延迟时间最小的CPU获得该锁。 采用二进制指数补偿算法可以明显降低总线上的数据流量。这是因为，一方面，可以 将短时间内各CPU对锁的需求，在时间上进行不同程度的延迟，增加测试的成功率，减少 各CPU对锁的测试次数；另一方面，在锁不空闲时，也很大程度地减少各CPU对其进行 测试的频率。但是，该算法的缺点在于，锁被释放时，可能由于各CPU的测试指令的延迟\n\n2.待锁CPU等待队列机构 如何及时发现锁空闲，另一种同步机构一一锁等待队列机构很好地解决了这一问题。 323  计算机操作系统 这种机构的核心思想是：为每一个CPU配置一个用于测试的私有锁变量和一个记录待锁 CPU的待锁清单，存放在其私有的高速缓存中。当多个CPU需要互斥访问某个共享数据结 构时，如果该结构已被占用，则为第一个未获得锁的CPU分配一个锁变量，并且将之附在 占用该共享数据结构CPU的待锁清单末尾：再为第二个未获得锁的CPU也分配一个锁变 量，并且将之附在待锁清单中第一个待锁CPU的后面；·…..\"；为第n个未获得锁的CPU 分配一个其私有的锁变量，并且将之附在待锁清单中第n-1个CPU的后面，形成一个待 锁CPU等待队列。当共享数据结构的占有者CPU退出临界区时，从其私有的高速缓存中 查找待锁清单，并释放第一个CPU的私有锁变量，允许它进入临界区，第一个CPU操作 完成后，也对其锁变量和第二个待锁CPU的锁变量进行释放，让第二个CPU进入其临界 区，依此类推，直至第n个待锁CPU进入其临界区。 在整个过程中，每一个待锁CPU都仅是在自己的高速缓存中，对其私有的锁变量进行 不断的测试，不会对总线进行访问，减少了总线的流量。同时，一旦锁空闲，便由释放该 锁的CPU通过修改其待锁清单中的下一个待锁CPU的锁变量的方法，及时通知下一个待 锁CPU进入临界区，从而避免了资源空闲而造成的浪费。"
          },
          {
            "三级标题": "10.4.5 定序机构 在多处理机系统和分布式系统中，有着许多的处理机或计算机系统，每个系统中都有 自己的物理时钟。为了能对各系统中的所有特定事件进行排序，以保证各处理机上的进程 能协调运行，在系统中应有定序机构。",
            "正文": "1.时间邮戳定序机构（TimestampOrderingMechanism） 对时间邮戳定序机构最基本的要求是，在系统中应具有唯一的、由单一物理时钟驱动 的物理时钟体系，确保各处理机时钟间的严格同步。该定序机构的基本功能是：\n\n（1）对所有的特殊事件，如资源请求、通信等，加印上时间邮戳；\n\n（2）对每一种特殊事件，只能使用唯一的时间邮戳；\n\n(3）根据事件上的时间邮戳，定义所有事件的全序。 利用时间邮戳定序机构，再配以相应的算法，可实现不同处理机的进程同步。实际上， 许多集中式和分布式同步方式，都是以时间邮戳定序机构作为同步机构的基础。\n\n2.事件计数（EventCounts）同步机构 在这种同步机构中，使用了一个称为定序器（Sequencers)的整型量，为所有特定事件进 行排序。定序器的初值为O，且为非减少的，对其仅能施加ticket(S）操作。当一个事件发生 时，系统便为之分配一个称为编号（或标号）V的序号，然后使ticket自动加1，一系列的ticket 操作形成了一个非负的、增加的整数序列，然后把打上标号的事件送至等待服务队列排队。 与此同时，系统将所有已服务事件的标号保留，并形成一个称为事件计数E的栈。实际上， E是保存已出现的某特定类型事件编号计数的对象（Object)，其初值为0，当前值是栈顶的 标号。对于事件计数，有下面三种操作： 1)await(E，V) 每当进程要进入临界区之前，先执行await操作，如果E<V，将执行进程插入到EQ 队列，并重新调度；否则进程继续执行。await可定义如下： 324  第十章多处理机操作系统 await(E,V) { if(E<V){ i=EP; stopO; i->status=\"block\"; i->sdata=EQ; insert(EQ,i); schedulerO; else continue; 1 2) advance(E) 每当进程退出临界区时，应执行advance(E)操作，使E值增1。如果EQ队列不空，则 进一步检查队首进程的V值；若E=V，则唤醒该进程。advance(E)操作可描述如下： advance(eventcountE){ E=E+1; if (EQ<>NIL) { V=inspect(EQ,1); if (E==V) wakeup(EQ,1); 1 一个进程执行临界区的操作序列为： await(E,V); Accessthecriticalresources; advance(E); 3) read(E) 返回E的当前值，提供给进程参考，以决定是否要转去处理其它事件。如果设计得当， 允许await、read和advance这三个操作，在同一事件上并发执行，但对定序器必须互斥使用。"
          },
          {
            "三级标题": "10.4.6 面包房算法 → 该算法是最早的分布式进程同步算法，是利用事件排序的方法对要求访问临界资源的 全部事件进行排序，按照FCFS次序对事件进行处理。该算法可以非常直观地类比为顾客 去面包店采购：面包店只能接待一位顾客，已知有n位顾客要进入面包店，安排他们按照 次序在前台登记一个签到号码，签到号码逐次加1；顾客根据签到号码由小到大的顺序， 依次入店购买；完成购买的顾客在前台把其签到号码归0。如果完成购买的顾客需再次进 店购买，必须重新排队。该算法的基本假定如下：",
            "正文": "（1）系统由N个结点组成，每个结点只有一个进程，仅负责控制一种临界资源，并处 理那些同时到达的请求。\n\n(2）每个进程保持一个队列，用来记录本结点最近收到的消息，以及本结点自已产生 325  计算机操作系统 的消息。\n\n(3）消息分为请求消息、应答消息和撤销消息三种，每个进程队列中的请求消息根据 事件时序排序，队列初始为空。\n\n(4）进程Pi发送的请求消息形如request(Ti，i)，其中 Ti=Ci，是进程Pi发送此消息时 对应的逻辑时钟值，i代表消息内容。 面包房算法描述如下：\n\n(1）当进程Pi请求资源时，它把请求消息request(Ti,i)排在自己的请求队列中，同时也 把该消息发送给系统中的其它进程；\n\n(2）当进程Pj接收到外来消息request(Ti,i)后，发送回答消息reply(Tj,j)，并把request(Ti,i) 放入自己的请求队列。应当说明，若进程Pj在收到request(Ti，i)前已提出过对同一资源的 访问请求，那么其时间戳应比（Ti，i)小。\n\n(3）若满足下述两条件，则允许进程Pi访问该资源（即允许进入临界区）： ·Pi自身请求访问该资源的消息已处于请求队列的最前面； ·Pi已收到从所有其它进程发来的回答消息，这些回答消息的时间戳均晚于（Ti，i)。\n\n（4）为了释放该资源，Pi从自己的队列中撤销请求消息，并发送一个打上时间戳的释 放消息release给其它进程；\n\n(5）当进程Pj收到Pi的release消息后，它撤销自己队列中的原Pi的request(Ti,i)消息。"
          },
          {
            "三级标题": "10.4.7 令牌环算法 一一一一一一→ 该算法属于分布式同步算法，是将所有进程组成一个逻辑环(LogicalRing)，系统中设 置一个象征存取权力的令牌（Token)，它是一种特定格式的报文，在进程所组成的逻辑环中， 不断地循环传递，获得令牌的进程，才有权力进入临界区，访问共享资源。 个进程获得令牌时，如果不需要访问共享资源，则将令牌继续传递下去。否则，保持令牌， 对共享资源进行检查，如果其空闲，则进入临界区进行访问。访问结束退出临界区后，再 将令牌继续传递下去。进程利用令牌，每次只能访问一次共享资源。 显然，由于令牌只有一个，任何一个时刻，只有一个进程能够持有令牌，因此能实现 对共享资源的互斥访问。 为保证环中进程能实现对共享资源的访问，逻辑环中的令牌必须保持循环传递和不丢 失，如果因通信链路、进程故障等原因造成令牌被破坏或丢失，必须有机制及时修复，比 如重新颁发令牌，或者屏蔽故障进程，重构逻辑环等。该算法的不足之处在于，如果令牌 丢失或破坏，不便进行检测和判断。",
            "正文": ""
          }
        ]
      },
      {
        "二级标题": "10.5_多处理机操作系统的进程调度",
        "三级内容": [
          {
            "三级标题": "10.5.1 评价调度性能的若干因素 一 评价多处理机调度性能的因素有如下几个：",
            "正文": "1.任务流时间 把完成任务所需要的时间定义为任务流时间，例如，如图10-6所示，图中有三台处理 机P1～P3和五个任务T1～T5，调度从时间0开始，共运行了7个时间单位，在处理机P1 上运行任务T1和T2，分别需要5个和1.5个时间单位；在处理机P2上运行任务T2和 T1，分别用了5个和2个时间单位；在处理机P3上运行任务T3、T4和T5，每一个都需 要2个时间单位。因此，完成任务T1共需要5+2=7个时间单位，而完成任务T2共需 要5+1.5=6.5个时间单位。 P1 T1 T2 P2 T2 T1 P3T3T4 T5 —$ 时间 0123456 图10-6任务流和调度流示意图\n\n2.调度流时间 在多处理机系统中，任务可以被分配到多个处理机上去运行。一个调度流时间是系统 中所有处理机上的任务流时间的总和。在如图10-6所示的例子中，在三台处理机上，调度 流时间=T1流+T2流+T3流+T4流+T5流=7+6.5+2+2+2=19.5（个时间单位）。\n\n3.平均流 平均流等于调度流时间除以任务数。平均流时间越小，表示任务占用处理机与存储器 等资源的时间越短，这不仅反应了系统资源利用率高，而且还可以降低任务的机时费用。 更为重要的是，还可使系统有更充裕的时间处理其它任务，有效地提高了系统的吞吐量。 因此，最少平均流时间就是系统吞吐率的一个间接度量参数。\n\n4.处理机利用率 处理机的利用率等于该处理机上任务流之和除以最大有效时间单位。在如图10-7所示的 例子中，最大有效时间单位为7.0，三台处理机P1、P2、P3的空闲时间分别为0.5、0.0和1.0， 忙时间分别为6.5、7.0、6.0，它们为各处理机上的任务流之和。由此可以得到P1、P2、P3 的处理机利用率分别为0.93、1.00和0.86。处理机平均利用率=（0.93+1.00+0.86）÷3=0.93。\n\n5.加速比 加速比等于各处理机忙时间之和除以并行工作时间，其中，各处理机忙时间之和，相 开始到最后一个任务结束所用的时间，在上例中为7个时间单位。由此得到加速比为19.5 个时间单位/7个时间单位。 加速比用于度量多处理机系统的加速程度。处理机台数越多，调度流时间越大，与单 327  计算机操作系统 机相比其完成任务的速度越快，但是较少的处理机可减少成本。对于给定的任务，占用较 少的处理机可腾出更多的处理机，用于其它任务，从而使系统的总体性能得到提高。\n\n6.吞吐率 吞吐率是单位时间（例如每小时)内系统完成的任务数。可以用任务流的最小完成时间 来度量系统的吞吐率。吞吐率的高低与调度算法有着十分密切的关系，通常具有多项式复 杂性的调度算法是一个高效的算法。而具有指数复杂性的调度算法则是一个低效算法。在 很多情况下，求解最优调度是NP完全性问题（NondeterministicPolynomial问题），意味着在 最坏情况下求解最优调度是非常困难的。但如果只考虑典型输入情况下的一个合适解，则 并不是一个难解的NP问题，因此，可以得到一组并行进程的合适调度。一般所说的优化 调度或最优调度，实际上均是指合适调度。"
          },
          {
            "三级标题": "10.5.2 进程分配方式",
            "正文": "1.对称多处理机系统中的进程分配方式 在SMP系统中，所有的处理机都是相同的，因而可把所有的处理机作为一个处理机池 (Processorpool)，由调度程序或基于处理器的请求，将任何一个进程分配给池中的任何一个 处理机去处理。对于这种进程分配，可采用以下两种方式之一。 1）静态分配（StaticAssigenment)方式 时，须为每一处理器设置一专用的就绪队列，该队列中的诸进程先后都是被分配到该处理 器上执行。在进程阻塞后再次就绪时，也仍被挂在这个就绪队列中，因而下次它仍在此处 理器上执行。这种方式与单处理机环境下的进程调度一样。其优点是进程调度的开销小；缺 点是会使各处理器的忙闲不均。换言之，系统中可能有些处理机的就绪队列很快就变成空 队列，使处理器处于空闲状态，而另一些处理器则可能一直忙碌。 2）动态分配（DynamicAssgement)方式 为了防止系统中的多个处理器忙闲不均，可以在系统中仅设置一个公共的就绪队列， 系统中的所有就绪进程都被放在该队列中。分配进程时，可将进程分配到任何一个处理器 上。这样，对一个进程的整个运行过程而言，在每次被调度执行时，都是随机地被分配到 当时是空闲的某一处理器上去执行。例如，某进程一开始是被分配到处理器A上去执行， 后来因阻塞而放弃处理器A。当它又恢复为就绪状态后，就被挂到公共的就绪队列上，在 下次被调度时，就可能被分配到处理器B上去执行，也有可能被分配到处理器C或处理器 D上去执行。人们把这种方式称为动态分配方式。 动态分配方式的主要优点是消除了各处理器忙闲不均的现象。对于紧密耦合共享存储 器的MIPS，其每个处理器保存在存储器中的进程信息可被所有的处理器共享。因此这种调 度方式不会增加调度开销。但对于松散耦合的系统，在把一个在处理器A上运行的进程转 至在处理器B上运行时，还必须将在A处理器中所保存的该进程信息传送给处理器B，这 无疑会造成调度开销的明显增加。\n\n2.非对称MPS中的进程分配方式 对于非对称MPS，其Os大多采用主一从(MasterSlave)式OS，即OS的核心部分驻留 328  第十章多处理机操作系统 在一台主机上(Master)，而从机(Slave)上只是用户程序，进程调度只由主机执行。每当从机 空闲时，便向主机发送一索求进程的信号，然后，便等待主机为它分配进程。在主机中保 持有一个就绪队列，只要就绪队列不空，主机便从其队首摘下一进程分配给请求的从机。 从机接收到分配的进程后便运行该进程，该进程结束后从机又向主机发出请求。 在非对称MPS中，主/从式的进程分配方式的主要优点是系统处理比较简单，这是因 为所有的进程分配都由一台主机独自处理，使进程间的同步问题得以简化，且进程调度程 序也很易于从单处理机的进程调度程序演化而来。但由一台主机控制一切，也潜在着不可 靠性，即主机一旦出现故障，将会导致整个系统瘫痪，而且也很易于因主机太忙，来不及 处理而形成系统瓶颈。克服这些缺点的有效方法是利用多台而非一台处理机来管理整个系 运行，而且用多台处理机（主）还可具有更强的执行管理任务的功能，更不容易形成系统瓶颈。"
          },
          {
            "三级标题": "10.5.3 进程（线程)调度方式 +一： MPS已广为流行多年，相应地，也必然存在着多种调度方式，特别是自20世纪90年 代以来，已出现了多种调度方式，其中有许多都是以线程作为基本调度单位的。比较有代 表性的进（线）程调度方式有：自调度方式、成组调度方式和专用处理机分配方式等。",
            "正文": "1.自调度（Self-Scheduling)方式 1）自调度机制 在多处理器系统中，自调度方式是最简单的一种调度方式。它是直接由单处理机环境 下的调度方式演变而来的。在系统中设置有一个公共的进程或线程就绪队列，所有的处理 器在空闲时，都可自己到该队列中取得一进程（或线程）来运行。在自调度方式中，可采用 在单处理机环境下所用的调度算法，如先来先服务（FCFS）调度算法、最高优先权优先（FPF) 调度算法和抢占式最高优先权优先调度算法等。 1990年，Leutenegger等人曾对在多处理机环境下的FCFS、FPF和抢占式FPF三种调 度算法进行了研究，发现在单处理机环境下，FCFS算法并不是一种好的调度算法。然而在 多处理机系统中把它用于线程调度时，FCFS算法又反而优于其它两种算法。这是因为，线 程本身是一个较小的运行单位，继其后而运行的线程不会有很大的时延，加之在系统中有 多个处理机（如N个)，这使后面的线程的等待时间又可进一步减少为1/N。FCFS算法简单、 开销小，目前已成为一种较好的自调度算法。 2）自调度方式的优点 自调度方式的主要优点表现为：首先，系统中的公共就绪队列可按照单处理机系统 中所采用的各种方式加以组织；其调度算法也可沿用单处理机系统所用的算法，亦即， 很容易将单处理机环境下的调度机制移植到多处理机系统中，故它仍然是当前多处理机 系统中较常用的调度方式。其次，只要系统中有任务，或者说只要公共就绪队列不空， 就不会出现处理机空闲的情况，也不会发生处理机忙闲不均的现象，因而有利于提高处 理机的利用率。 3）自调度方式的缺点 自调度方式的缺点不容忽视，主要表现如下： 329  计算机操作系统\n\n（1）瓶颈问题。在整个系统中只设置一个就绪队列，供多个处理器共享，这些处理器 必须互斥地访问该队列，这很容易形成系统瓶颈。这在系统中处理器数目不多时，问题并 不严重；但若系统中处理器数目在数十个乃至数百个时，如果仍用单就绪队列，就会产生 严重的瓶颈问题。\n\n(2）低效性。当线程阻塞后再重新就绪时，它将只能进入这唯一的就绪队列，但却很 少可能仍在阻塞前的处理器上运行。如果在每台处理器上都配有高速缓存（Cache），则这时 数据的拷贝。由于一个线程在其整个生命期中可能要多次更换处理器，因而使高速缓存的 使用效率很低。\n\n（3）线程切换频繁。通常，一个应用中的多个线程都属于相互合作型的，但在采用自 调度方式时，这些线程很难同时获得处理器而同时运行，这将会使某些线程因其合作线程 未获得处理器运行而阻塞，进而被切换下来。\n\n2.成组调度（GangScheduling）方式 为了解决在自调度方式中线程被频繁切换的问题，Leutenegger提出了成组调度方式。 该方式将一个进程中的一组线程分配到一组处理器上去执行。在成组调度时，如何为应用 程序分配处理器时间，可考虑采用以下两种方式： 1）面向所有应用程序平均分配处理器时间 每个应用程序至多可有1/M的时间去占有N个处理机。例如，有4台处理器及两个应用程 序，其中，应用程序A中有4个线程，应用程序B中有一个线程。这样，每个应用程序可 占用4台处理机一半（1/2)的时间。图10-7(a)示出了此时处理器的分配情况。由图可看出， 使用这种分配方式，在应用程序A运行时，4台处理器都在忙碌；而应用程序B运行时， 则只有1台处理器忙碌，其它3台空闲。因此，将有3/8的处理器时间（即37.5%）被浪费了。 应用程序A 应用程序B 应用程序A 应用程序B 处理器1 线程1 线程1 处理器1 线程1 线程1 空闲 处理器2 线程2 处理器2 线程2 空闲 处理器3 线程3 空闲 处理器3 线程3 空闲 处理器4 线程4 空闲 处理器4 线程4 空闲 1/2 1/2 4/5 1/5 (a)浪费37.5% (b)浪费15% 图10-7两种分配处理机时间的方法 2）面向所有线程平均分配处理机时间 由于应用程序A中有4个线程，应用程序B中只有1个线程，因此，应为应用程序A 分配4/5的时间，只为应用程序B分配1/5的时间，如图10-7(b）所示。此时，将只有15% 的处理机时间被浪费。可见，按线程平均分配处理机时间的方法更有效。 成组调度方式的主要优点是：如果一组相互合作的进程或线程能并行执行，则可有效 地减少线（进）程阻塞情况的发生，从而可以减少线程的切换，使系统性能得到改善；此外， 330  第十章多处理机操作系统 因为每次调度都可以解决一组线程的处理机分配问题，因而可以显著地减少调度频率，从 而也减少了调度开销。可见，成组调度的性能优于自调度，目前已获得广泛的认可，并被 应用到许多种处理机OS中。\n\n3.专用处理机分配（DedicatedProcessorAssigement)方式 1989年Tucker提出了专用处理机分配方式。该方式是指在一个应用程序的执行期间， 专门为该应用程序分配一组处理机，每一个线程一个处理机。这组处理机仅供该应用程序 专用，直至该应用程序完成。很明显，这会造成处理机的严重浪费。例如，有一个线程为 了和另一线程保持同步而阻塞起来时，为该线程所分配的处理机就会空闲。但把这种调度 方式用于并发程度相当高的多处理机环境，则是根据下述一些理由： 首先，在具有数十个乃至数百个处理机的高度并行的系统中，每个处理机的投资费用 在整个系统中只占很小一部分。对系统的性能和效率来说，单个处理机的利用率已远不像 在单机系统中那么重要。 其次，在一个应用程序的整个运行过程中，由于每个进程或线程专用一台处理机，因 此可以完全避免进程或线程的切换，从而大大加速了程序的运行。 Tucker在一个具有16个处理机的系统中，运行两个应用程序：一个是矩阵相乘程序，另 图10-8中示出了应用程序的加速比（Speedup）与线程数目之间的关系。当每个应用程 序中含有7～8个线程时，可获得最高加速比；当每个应用程序中的线程数大于8个时，加 正好是每个线程能分得1台处理器；当超过8个线程时，就不能保证每个线程有1台处理 器，因而会出现线程切换问题。可见，线程数愈多时切换就愈频繁，反而会使加速比下降。 因此，Tucker建议：在同时加工的应用程序中，其线程数的总和，不应超过系统中处理机 的数目。 加速比 一一一矩阵相乘 FFT 6 5 3 2 1 10 20 线程数 图10-8线程数对加速比的影响 由许多相同处理器构成的同构型多处理机系统，其处理器的分配酷似单机系统中的请 求调页式内存分配。例如，在某时刻，应把多台处理器分配给某应用程序的问题，十分类 似于将多少个内存物理块分配给某进程的问题。又如，在进行处理器分配时，又存在着一 331  计算机操作系统 个活动工作集的概念，它又类似于请求调页中的工作集概念。当所分配的处理器数少于活 动工作集时，将会引起线程的频繁切换，这很类似于在请求调页时，所分配的物理块数若 少于其工作集数时，便会引起页面频繁调进调出的情况。\n\n4.动态调度 该调度方式允许进程在执行期间动态地改变其线程的数目。这样，操作系统和应用程 序能够共同地进行调度决策。操作系统负责把处理机分配给作业，而每个作业负责将分配 到的处理机再分配给自己的某一部分可运行任务。 在这种方法中，操作系统的调度责任主要限于处理机的分配，并遵循以下的原则：\n\n（1）空闲则分配。当一个或多个作业对处理机提出请求时，如果系统中存在空闲的处 理机，就将它（们)分配给这个(些）作业，满足作业的请求。\n\n(2）新作业绝对优先。所谓新作业，是指新到达的，还没有获得任何一个处理机的作 业。对于多个请求处理机的作业，首先是将处理机分配给新作业，如果系统内已无空闲处\n\n（3）保持等待。如果一个作业对处理机的请求，系统的任何分配都不能满足，作业便 保持未完成状态，直到有处理机空闲，可分配予之使用，或者作业自已取消这个请求。\n\n(4）释放即分配。当作业释放了一个(或多个)处理机时，将为这个(或这些)处理机扫描 处理机请求队列，首先为新作业分配处理机，其次按先来先服务（FCFS)原则，将剩余处理 机进行分配。 动态调度方式优于成组调度和专用处理机调度方式，但其开销之大，有可能抵消它的 一部分优势，所以在实际应用时，应精心设计具体的调度方法。"
          },
          {
            "三级标题": "10.5.3 死锁 一一 在多处理机系统中，产生死锁的原因以及对死锁的防止、避免和解除等基本方法与单 处理机相似，但难度和复杂度增加很多。尤其是在NUMA分布式环境下，进程和资源在配 置和管理上呈现了分布性，竞争资源的各个进程可能来自不同结点。但是，在每个资源结 点，通常仅记录本结点的资源使用情况，因此，来自不同结点的进程在竞争共享资源时， 对于死锁的检测显得十分困难。",
            "正文": "1.死锁的类型 在多处理机系统中，死锁可以分成资源死锁和通信死锁。前者是因为竞争系统中可重 复使用的资源（如打印机、磁带机、存储器等）时，由于进程的推进顺序不当引起的。如集 中式系统中，如果进程A发送消息给B，进程B发送消息给C，而进程C又发送消息给 A，那么就会发生死锁。而后者，主要是在分布式系统中，由于处于不同结点中的进程， 即发生了通信死锁。\n\n2.死锁的检测和解除 有两种检测方法：集中式检测和分布式检测。 1）集中式检测 在每台处理机上都有一张进程资源图，用于描述进程及其占有资源的状况，在负责控 332  第十章多处理机操作系统 制的中心处理机上，配置一张整个系统的进程资源图，并设置一个检测进程，负责整个系 统的死锁检测。当检测进程检测到环路时，就选择中止环路中的一个进程，以解决死锁。 为了及时获得最新的进程和资源状况，检测进程对各个结点更新信息的获得，可以通 过三种方式：①当资源图中加入或删除一条弧时，相应的变动消息就发送给检测进程； ②每个进程将新添加或删除的弧的信息周期性地发送给检测进程；③检测进程主动去请 求更新信息。 上述方式有个不足之处在于，由于进程发出的请求与释放资源命令的时序与执行这两 条命令的时序有可能不一致，以至于在进程资源图中形成了环形链，然而是否真的发生了 死锁，却无法判断。对此，一种合适的解决办法是：当检测进程发现这种情况后，需要再 则确认为假死锁。 2）分布式检测 分布式检测是通过系统中竞争资源的各个进程间的相互协作，实现对死锁的检测，无 需设置一个检测进程，专门用于对全局资源使用情况进行检测。该方式在每个结点中都设 排队，在一个进程对某资源操作前，必须先向所有其它进程发送请求信息，在获得这些进 程的响应信息后，才把请求资源的消息发给该资源的管理进程。每个进程都要将资源的已 分配情况通知所有进程。 由上述可见，对于分布式环境下的死锁检测，需要的通信开销较大，在实际应用中， 往往采取的是死锁预防方式。"
          }
        ]
      },
      {
        "二级标题": "10.6_网络操作系统",
        "三级内容": [
          {
            "三级标题": "10.6.1 ：网络及网络体系结构",
            "正文": "1.计算机网络的组成 计算机网络从构造的物理结构而言，是通过包括星形、树形、公用总线形、环形和网 状形等不同的拓扑结构，将地理上分散的计算机连接起来的网络。而从逻辑结构而言，计 算机网络是由三个部分组成：\n\n（1）通信子网：由分布在不同地点的、负责数据通信处理的通信控制处理机与通信线 路互连构成，是计算机网络的基础部分，主要负责数据的传输及交换。\n\n(2）资源子网：由负责数据处理的主计算机与终端构成，作为计算机网络中的信源和 信宿，都连接在通信子网中的一个交换设备上，构成了建立在通信子网上的资源子网，负 333  计算机操作系统 责进行数据处理。\n\n(3）网络协议：为实现计算机网络中的数据交换而建立的规则、标准或约定的集合， 是为了保证网络中源主机系统和目标主机系统保持高度一致的协同。\n\n2.网络协议 网络协议是一组控制数据交互过程的通信规则，规定了通信双方所交换数据(控制信息) 的格式和时序。网络协议的三要素分别是：\n\n（1）语义，解释控制信息每个部分的意义，规定了通信双方要发出的控制信息、执行 的动作和返回的应答等；\n\n（2）语法，规定通信双方彼此应该如何操作，即确定协议元素的格式，包括用户数据 与控制信息的结构与格式，以及数据出现的顺序；\n\n（3）时序，对事件发生顺序的详细说明，指出事件的顺序和速率匹配等。 在网络的每一层中都有相应的网络协议。（N)协议是指一组局部于(N)层的协议，它决 定着(N)实体在执行(N)功能时的通信行为。 计算机网络中存在有多种协议，每个协议应该处理没有被其它协议处理过的通信问题， （即内聚性高，耦合性低），同时每个协议之间可以共享数据和信息。 网络的协议具有两种形式：一是便于人进行阅读和理解的文字描述；二是能够让计算 机理解的程序代码。两种不同形式的协议都必须能够对网络上交换的信息做出精确的解释 和规定。\n\n3.互连网协议IPv4和IPv6 1）IPv4协议 IPv4是早期在Internet上使用的网络互连协议，可利用它来实现网络互连，为此，IPv4 实体，应为这些实体赋予全局性标识符；②分段和重新组装，在不同的网络中，所规定的 顿长度并不相同，例如在X.25网中优先选用的最大长度为128个字节，而在以太网中则为 1518个字节，这样，当信息从以太网送入X.25网时，就应先进行分段，在由WAN把信息 传送到目标LAN后，又应对它们进行重新组装；③源路由选择，为IP数据报的传输，选 择最佳的传输路由。 2)IPv6协议 IPv6协议继承了IPv4协议的一切优点，而针对其不足之处做了多方面的修改，使之 能更好地满足当今Internet网络的需要。如扩大了地址空间，IPv4协议的规定地址长度为 4个字节，而在IPv6协议中的地址长度已扩充到16个字节；又如增设了安全机制，在IPv6 协议中引入了认证技术，以保证被确认的用户仅能去做已核准他执行的操作等。\n\n4.传输层协议TCP和UDP 1）传输控制协议TCP TCP提供了面向连接的、可靠的端-端通信机制。所谓可靠，是指即使网络层（通信子 网)出现了差错，TCP协议仍能正确地控制连接的建立、数据的传输和连接的释放。此外， 在进行正常的数据交换时也要有流量控制，即控制发方发送数据的速度不应超过接收方接 收数据的能力。 334  第十章多处理机操作系统 2）用户数据报协议UDP 如果所传输的数据并不那么重要，可考虑利用UDP协议来传输数据。该协议是一种无 连接的、不可靠的协议。它无需在数据传送之前先建立端-端之间的连接，也就不要拆除连 接。在数据传送过程中，无需对传送的数据进行差错检测。换而言之，它是以一种比较简 单的方式来传送数据，因而有效地提高了传输速率。\n\n5.网络体系结构 为了简化对复杂的计算机网络的研究、设计和分析工作，一般把计算机网络的功能分 成若干层。层次结构就是指把一个复杂的系统设计问题分解成多个层次分明的局部问题， 并规定每一层次所必须完成的功能。 计算机网络的体系结构就是这个计算机网络及其部件所应完成功能的精确定义，是针 之间的互连、互通和互操作提供相应的规范和标准(即协议)。网络体系结构是抽象的，而 实现网络协议的技术是具体的。 在开放系统互连参考模型OSI/RM(OpenSystemInterconnection/ReferenceModel)的网 络体系结构中，从最低物理层，到最高应用层共分为七层，如图10-9所示，各层的功能 如下：\n\n（1）物理层（PhysicalLayer)：是OSI的最低层，建立在通信介质的基础上，实现系统和 通信介质的接口功能，为数据链路实体之间透明地传输比特流提供服务。\n\n(2）数据链路层(DataLinkLayer)：是在相邻两系统的网络实体之间，建立、维持和释 放数据链路连接，在两个相邻系统的网络实体之间实现透明的、可靠的信息传输服务。数 据传输的基本单位是帧。\n\n（3）网络层（NetworkLayer)：网络层主要涉及通信子网及与主机的接口，提供建立、维 持和释放网络连接的手段，以实现两个端系统中传输实体间的通信。传输的基本单位是分 组（packet)。\n\n（4）传输层（TransportLayer）：为不同系统内的会唔实体间建立端-端（end-to-end)的透 明、可靠的数据传输，执行端-端差错控制及顺序和流量控制，管理多路复用等。数据传输 的基本单位是报文(message)。 主机系统 主机系统 应用层协议 应用层 表示层协议 表示层 会唔层协议 会唔层 传输层协议 传输层 网络层 网络层 数据链路层 数据链路层 物理层 物理层 物理介质 图10-9OSI七层模型 335  计算机操作系统\n\n(5）会唔层(SessionLayer)：为不同系统内的应用进程之间建立会唔连接。会唔层的作 用是对基本的传输连接服务进行“增值”，以提供一个能满足多方面要求的会唔连接服务。\n\n(6）表示层(PresentationLayer)：向应用进程提供信息表示方式、对不同系统的表示方 法进行转换，使在采用不同表示方式的应用实体之间能进行通信，并提供标准的应用接口 和公用通信服务，如数据加密、正文压缩等。\n\n(7）应用层(ApplicationLsyer)：是OSI/RM中的最高层，它为应用进程访问OSI环境 提供了手段，并直接为应用进程服务，其它各层也都通过应用层向应用进程提供服务。 OSI参考模型层次划分的原则：①网络中各主机都具有相同的层次；②不同主机的 同等层具有相同的功能；③同一主机内相邻层之间通过接口通信：④每层可以使用下层提 供的服务，并向其上层提供服务；5不同主机的同等层通过协议来实现同等层之间的通信。"
          },
          {
            "三级标题": "10.6.2 网络操作系统及其分类",
            "正文": "1.网络操作系统及其特征 网络操作系统(NetworkOperatingSystem)是在计算机网络环境下，对网络资源进行管理 和控制，实现数据通信及对网络资源的共享，为用户提供与网络资源之间接口的一组软件 和规程的集合。网络操作系统建立在网络中计算机各自不同的单机操作系统之上，为用户 提供使用网络系统资源的桥梁。一般而言，网络操作系统具有下面5个特征。\n\n（1）硬件独立性：系统可以运行于各种硬件平台之上。例如，可以运行于Intelx86系 统，也可以运行于基于RISC精简指令集的系统，诸如DECAlpha、MIPSR4000等。\n\n(2）接口一致性：系统为网络中的共享资源提供一致性的接口，即对同一性质的资源 采用统一的访问方式和接口。\n\n(3）资源透明性：对网络中的资源统一管理，能够根据用户的要求，自动地分配和 选择。\n\n（4）系统可靠性：系统利用资源在地理上分散的优点，通过统一管理、分配和调度手 段，确保了整个网络的安全可靠。如果一个节点和通信链路出现故障，可以屏蔽该节点或 重新定义新的通信链路，保证网络的正常运行。\n\n（5）执行并行性：系统不仅实现了在每个节点计算机中各道进程的并发执行，而且实 现了网络中多个节点计算机上进程的并行执行。\n\n2.网络操作系统的分类 组建计算机网络的基本目的是共享资源，根据对共享资源不同的组织、控制和数据处 理方式，从历史发展来看，计算机网络应用模式可分为主从模式、对等模式和基于服务器 模式三类。其中的主从模式前面已经介绍过了，下面介绍其它两类。基于服务器模式又可 分为专用文件服务器模式（也称工作站服务器模式）、客户机服务器模式和浏览器服务器模 式。所以，对应地，将网络操作系统的工作模式也分为两大类共四种模式： 1）对等模式(peer-to-peer model) 服务器，任何一台计算机和其它计算机之间没有从属关系。原则上网络中的任意两个节点 之间都直接通信，系统中的每一台计算机都能访问计算机上的共享资源，每台联网计算机 336  第十章多处理机操作系统 都分前台方式和后台方式工作，前台为本地服务，后台为其它结点的网络用户服务。 该模式适用于较小范围和规模的网络，其优点在于结构简单，容易安装和维护，网络 中任意两个节点均可直接通信。其缺点在于对网络中每一个节点的计算机负载过重，既要 承担本地用户的信息处理任务，又要承担较重的网络共享资源管理和通信管理任务，明显 降低了信息处理能力。 2）工作站/服务器模式（Workstation/Servermodel) 该模式将网络中的节点计算机分为两类：网络服务器（Server)和网络工作站 （Workstation)。服务器以集中方式管理网络中的共享资源，为工作站提供服务，服务器不再 作其它用途。工作站为本地用户访问本地资源和访问网络资源服务。 非对等网络的操作系统的软件也分为两部分：一部分运行在服务器上，另一部分运行 在工作站上。服务器集中管理网络资源和服务，是局域网的逻辑中心。安装在服务器上的 网络操作系统软件的功能和性能决定了网络服务功能的强弱以及系统的性能和安全性，是 网络操作系统的核心部分，也称为基于专用服务器的网络操作系统。 绝大多数网络都是采用非对等结构的网络操作系统，可用于大型系统的联网。典型的 非对等结构网络操作系统有Novell公司的NetWare和Microsoft公司的WindowsNT等。 3）客户/服务器模式（Client/Servermodel） 在计算机网络中，从硬件角度看，客户/服务器模式是指，某项任务分配在两台或多台 机器上，其中用于接受请求并提供各种资源、数据和服务的计算机称为服务器，而面向用 户，提供用户接口和前端处理，并向服务器提出资源、数据和服务请求的计算机称为客 户机。 从软件角度看，客户/服务器模式是指，将某项应用或软件系统按逻辑功能，划分为客 户端软件和服务器软件两个部分。前者负责数据的表示和应用、用户界面的处理、接收用 户的数据处理请求、向服务器发出数据和服务请求。后者负责接收客户端软件发来的请求 并提供相应的服务。 客户与服务器之间采用网络协议（如TCP/IP、IPX/SPX）进行连接和通信，其交互模式 一般为：客户端向服务器发出请求，服务器端接收请求并执行相应服务，服务器回送响应 包，客户端接收响应包。 4）浏览器/服务器模式（Browser/Servermodel） 客户/服务器模式可分为两层C/S模式和三层C/S模式两种。传统的小型局域网采用两 层客户/服务器模式，在大型网络中通常采用三层C/S模式。三层C/S模式，即将客户机连 接到一台Web服务器（并配上浏览器软件，用于实现客户与Web服务器之间的交互）上，即 在客户机与服务器之间再增加一台Web服务器，它相当于前面所介绍的应用服务器。 当客户机需要访问各种服务器时，用户须先访问Web服务器，然后由Web服务器代理 客户去访问某台（些）服务器。由于配置了浏览器软件的客户机可以浏览网络中几乎所有允 许访问的服务器，这时便把这样的客户机称为Web浏览器，由此形成了Web浏览器、Web 服务器和数据库服务器三层的C/S模式，通常也称为浏览器/服务器模式。 浏览器与服务器之间的交互，与传统C/S之间的交互方式相似，都属于请求/响应方式， 337  计算机操作系统 所不同的是浏览器所检索的对象通常是超文本文件，因此在浏览器与Web服务器之间所采 用的是HTTP传输协议。"
          },
          {
            "三级标题": "10.6.3 网络操作系统的功能 网络操作系统不仅涵盖了单机操作系统的全部功能，还具有支持数据通信、应用互操 作、网络管理等功能。",
            "正文": "1.数据通信 为了实现网络中计算机之间的数据通信，网络OS应具有如下基本功能：\n\n（1）连接的建立与拆除。为实现两计算机系统之间的通信，需要在两个系统的多个层 次之间建立连接：①在相邻两个系统的物理层之间建立物理连接，为信息传输提供一条物 理传输路径；②在相邻结点的数据链路层间建立数据链路连接，以实现相邻结点间无差错 的信息传输；③在网络层中，又须在源传输实体和目标实体之间建立一条网络连接，直至 在两系统的表示层中，为两个应用实体建立了表示连接，即除应用层外的所有各层都要为 数据通信建立相应的连接。当通信结束后，又须将各层中的相应连接拆除。\n\n（2）报文的分解与组装。在源主机中将用户数据由传输层送至网络层之前，应将用户 数据（报文）分解成若干个适合在网络中传输的分组，然后逐个按序将它们送至网络层。再 由网络层把分组发送给网络中的下一个结点。当这些分组到达目标主机后，再由目标主机 中的传输层按分组序号，将这些分组重新组装成报文，再通过会唔层、表示层送给应用层 中的目标进程。\n\n(3）传输控制。为使用户数据（报文）能在网络中正常传输，必须为报文配上报头来控制报 文传输，报头中的内容是用于控制报文传输的信息，如目标地址、源主机地址、报文序号等。\n\n（4）流量控制。从源实体所发出数据的速度，不应超过目标实体接收和处理数据的能 力，以及链路的传输能力，这就是流量控制功能。\n\n(5）差错的检测与纠正：数据在网络中传输时难免会出现差错，为了减少数据在传输 过程中的错误，网络中必须有差错控制设施以完成检测差错（即发现数据在传输过程中所出 现的错误）和纠正错误（即对已发现的错误加以纠正）。\n\n2.应用互操作 为了实现多个网络之间的通信和资源共享，不仅需要将它们从物理上连接在一起，而 且还应使不同网络的计算机系统之间能进行通信（信息互通）和实现资源共享（信息互用）。为 此，在网络OS中必须提供应用互操作功能，以实现“信息互通性”及“信息互用性”。\n\n（1）信息的互通性。为了避免在不同的网络中，因采用了不同的协议而不能相互识别 和通信，在互连网络的每一个网络中都应配置同一类型的传输协议，以实现各个网络之间 的通信。如互连网络Internet（互联网），是由成千上万个各种类型的WAN互连而成的，所 有这些网络都是利用TCP/DP传输协议来实现信息互通的，如果用户希望把自己的网络连接 到Internet上，就必须在自己的网络中配置TCP/IP传输协议。\n\n(2）信息的“互用性”。所谓信息的“互用性”，是指在不同的网络中的站点之间能实 现信息的互用，亦即一个网络中的用户能够访问另一个网络文件系统（或数据库系统）中的 文件（数据）。不能实现信息的“互用性”的原因是，在不同网络中所配置的网络文件系统（或 338  第十章多处理机操作系统 数据库系统），通常都使用了各不相同的结构、各不相同的文件命名方式和存取文件的命令， 于是便发生了由一个源网络中的用户发往一个目标网络去的文件访问命令不能被目标网络 上的结点所识别的情况。对此，一个当前相对比较流行的解决方案是由SUN公司推出的网 络文件系统协议NFS(NetworkFileSystem)。\n\n3.网络管理 在网络中引入了网络管理功能，以确保能最大限度地增加网络的可用时间，提高网络 设备的利用率，改善网络的服务质量，以及保障网络的安全性等。 1）网络管理的目标\n\n（1）增强网络的可用性，如通过预测及时地检测出网络故障，为关键设备配置余的 设备等；\n\n(2）提高网络的运行质量，随时监测网络中的负荷及流量；\n\n(3）提高网络的资源利用率，长期监测网络，对网络资源进行合理的调整；\n\n（4）保障网络数据的安全性，采取多级安全保障机制；\n\n（5）提高网络的社会和经济效益。 2）网络管理的功能 ISO为网络管理定义了差错、配置、性能、计费和安全五大管理功能：\n\n（1）配置管理，用来监控网络的配置数据，允许网络管理人员能生成、查询和修改软 硬件的运行参数和条件，以保证网络正常运行；\n\n(2）故障管理，通常用来检测网络中所发生的异常事件，为网络操作员提供快速发现 和修复故障的手段；\n\n(3）性能管理，通过收集网络运行数据，分析网络的运行情况以及网络的运行趋势， 得出对网络的整体和长期的评价，将网络性能控制在用户能接受的水平；\n\n(4）安全管理，提供某种安全策略来控制对资源的访问，包括定义合法操作员及其权 限和管理域，规定用户对网络资源的访问权限，通过使用日志等手段对所关心的事件进行 调查，防止病毒等；\n\n(5）计费管理，用于监视和记录用户使用网络资源的种类、数量和时间，对资源的使 用进行计费。"
          }
        ]
      },
      {
        "二级标题": "10.7_分布式文件系统",
        "三级内容": [
          {
            "三级标题": "10.7.1 分布式系统 一←",
            "正文": "1.分布式系统的特征 分布式系统(distributedsystem)，是基于软件实现的一种多处理机系统，是多个处理机 通过通信线路互连而构成的松散耦合系统，系统的处理和控制功能分布在各个处理机上。 换言之，是利用软件系统方式构建在计算机网络之上的一种多处理机系统。 与前面所述的多种多处理机系统（包括多处理机和多计算机等）相比，分布式系统的不 同在于：①分布式系统中的每个节点都是一台独立的计算机，并配置有完整的外部设备； ②分布式系统中节点的耦合程度更为分散，地理分布区域更加广阔；③分布式系统中的 还有其它多个机构对其实施管理。 对分布式系统有很多不同的定义，比如：“一个分布式系统是一些独立的计算机集合，但 是对这个系统的用户来说，系统就像一台计算机一样”，或者，“分布式系统是能为用户自动 算机系统一样对用户是透明的。”等等，归纳起来，分布式系统应具有以下几个主要特征：\n\n(1）分布性。系统由多台计算机组成，从位置和地域范围而言，是分散且广阔的，即 地理位置的分布性。从系统的功能而言，是分散在系统的各个节点计算机上，即功能的分 布性。从系统的资源而言，也是分散配置在各节点计算机上，即资源的分布性；从系统的 控制而言，一般的分布式系统中计算机没有主、从之分，即控制的分布性。其中，资源和 控制的分布性也称自治性。\n\n(2）透明性。系统资源被所有计算机共享。每台计算机的用户不仅可以使用本机的资 源，还可以使用分布式系统中其它计算机的资源(包括CPU、文件、打印机等)。\n\n(3）同一性。系统中的若干台计算机可以互相协作来完成一个共同的任务，或者说一 个程序可以分布在几台计算机上并行地运行。\n\n（4）全局性。系统具备一个全局性的进程通信机制，系统中的任意两台计算机都可以 通过该机制实现信息交换。\n\n2.分布式系统的优点 分布式系统与集中式系统相比具有以下一些优点：\n\n（1）计算能力强。由于采用了并行处理技术，可将任务划分为多个子任务，并将它们 分派到不同的计算机节点上并行执行，因此，分布式系统总的计算能力比单个的大型集中 式系统的计算能力强。\n\n(2）易于实现共享。分布式系统建立在计算机网络基础上，对于系统中的资源，很容 易实现共享。此外，由于系统具有计算迁移的功能，能够将任务迁移到不同的节点执行， 很容易实现负载共享。\n\n(3）方便通信。各节点通过通信网络连接，建立在计算机网络基础上，从系统底层到 高层都有多种成熟的通信机制和工具可以移植，加之分布式系统地域范围广阔的特点，为 人们之间的信息交流提供了很大的方便。 340  第十章多处理机操作系统\n\n(4）可靠性高。在分布式系统中，工作负载都分散在多台机器上，单个机器故障只会 使一台机器停机，而不会影响其它机器，从而获得很高的可靠性。\n\n(5）可扩充性好。在分布式系统中，可方便地添加若干台计算机，而不需对系统的软 硬件进行修改。 尽管分布式系统有很多优点，但也存在一些缺点，目前主要表现为可用软件不足。分 布式系统需要与集中式系统完全不同的软件，特别是系统所需要的分布式操作系统才刚刚 出现，导致如编程、工具和其它的应用软件的不足。另外，在通信网络方面的信息丢失、 网络安全方面的数据安全保密等存在一些潜在的不足。\n\n3.分布式操作系统 分布式操作系统是配置在分布式系统上的公用操作系统，以全局的方式对分布式系统 中的所有资源进行统一管理，可以直接对系统中地理位置分散的各种物理和逻辑资源进行 动态的分配和调度，有效地协调和控制各个任务的并行执行，协调和保持系统内的各个计 算机间的信息传输及协作运行，并向用户提供一个统一的、方便的、透明的使用系统的界 面和标准接口。一个典型的例子是万维网(WorldWideWeb)，在万维网中，所有的操作只通 过一种界面—Web页面。 与网络操作系统不同，分布式OS用户在使用系统内的资源时，不需要了解诸如网络 中各个计算机的功能与配置、操作系统的差异、软件资源、网络文件的结构、网络设备的 地址、远程访问的方式等情况，对用户屏蔽了系统内部实现的细节。分布式OS保持了网 络操作系统所拥有的全部功能，同时又具有透明性、内聚性、可靠性和高性能等特点。 分布式操作系统除了涵盖单机操作系统的主要功能外，还应该包括：\n\n（1）通信管理功能。分布式OS系统应提供某种通信机制和方法，使不同节点上的用户 或进程能方便地进行信息交换。一般地，分布式OS通过提供一些通信原语的方式，实现 系统内的进程通信，但由于系统中没有共享内存，这些原语需要按照通信协议的约定和规 则来实现。\n\n（2）资源管理功能。分布式OS对系统中的所有资源实施统一管理、统一分配和统一调 度，提高资源利用率，方便用户共享和使用。例如，提供不同节点用户共享的分布式文件 系统、分布式数据库系统、分布式程序设计语言及编译系统、分布式邮件系统等。\n\n（3）进程管理功能。针对系统分布性特征，为平衡各节点负载，加速计算速度，分布 式OS应提供进程或计算迁移；为协调进程对资源的共享和竞争，提高进程的并行程度， 应提供分布式的同步和互斥机制，以及应对死锁的措施等。"
          },
          {
            "三级标题": "10.7.2 分布式文件系统的实现方式和基本要求 一← 随着计算机性能的不断提升，部件平均价格的不断下降，尤其是网络技术的发展以及 应用的普及，基于光纤通道的NAS和SAN的广泛应用，极大地推动了DFS（分布式文件系 统)的研究和发展。对大容量、高性能的数据存储和共享的需求，推动着DFS管理规模的 扩大、系统的复杂程度的增高，出现了多种体系结构的实现方式，各种应用需求对系统提 出了更多的要求。",
            "正文": "1.DFS的实现方式 DFS有多种实现方式，一般分为以下两类： 341  计算机操作系统 1）共享文件系统方式（sharedfilesystemapproach) 该方式也称专用服务器方式。类似于本地文件系统使用树形目录结构，管理本地计算 机存储设备上的文件方式。共享文件系统方式也采用一个逻辑树的结构，对整个系统中的 文件系统进行管理。系统采用客户/服务器模式，设置了若干个文件服务器，数据分布地存 储在各个文件服务器上。用户可以忽略文件的实际物理位置，只需要按一定的逻辑关系， 通过文件服务器上的服务进程，即可访问整个系统（或网络）的共享资源。文件服务器的分 布和文件系统逻辑树的架构，对用户都是透明的，用户可以像访问本地文件一样访问分布 在多个节点上的文件。共享文件系统的方法已被许多分布式文件系统所采用，如NFS、AFS 和Sprite文件系统等。 该方式实现比较简单，对于设备的要求不高，而且通用性也比较好，在本书中主要讨 论这种实现方式。 2）共享磁盘方式(shareddiskapproach) 该方式也称为无服务器方式。在这种方式中，系统中没有专门的文件服务器，而是配 置了一个共享磁盘（一般为高速磁盘，如IBMSSA)，并将其与主机、客户机都连接在内部 的高速网络（如光通道）上，主机和客户机都将共享磁盘作为它们的存储设备，直接以盘块 方式读写磁盘上的文件，实现共享。使用该方式的有VAXCluster的文件系统、IBMGPFS 和GFS等。与共享文件系统方法相比，该方式对设备的要求高，实现的难度也要大些，往 往被用来构造高端或专用的存储设备，如NAS(NetworkAttachedStorage)和SAN(Storage AreaNetwork)等。\n\n2.基本要求 相对于LFS，DFS除了大容量的要求外，还有很多基本要求：\n\n(1）透明性，包括：①位置的透明性，文件服务器及文件服务进程的多重性，与共享 存储器的分散性，对客户透明；②移动透明性，存储资源和数据在系统内位置的移动和变 更对客户透明；③性能透明性，允许系统中的服务负载有一定范围的变化量，仍能对客户 提供相对稳定的性能保障；④扩展透明性，允许系统在规模、性能和功能上进行扩展，以 满足负载和网络规模的增长。\n\n(2）高性能和高可靠性，系统必须能够提供比本地文件系统更高的性能和可靠性，以 满足分布式文件系统中诸多客户繁重的访问需求，保证系统的安全可靠。\n\n(3）容错性，这是保证系统可靠性不可缺少的手段，在系统出现错误时，仍能为用户 提供服务。一般采用多种余技术实现对故障的掩盖，包括：①信息余，如增加校验信 息；②时间冗余，如重复执行操作；③物理允余，如增加额外的副本、设备或进程等。\n\n(4）安全性，通过身份验证、访问控制和安全通道等方式，保证系统的安全性。\n\n(5）一致性，保证客户在本地缓存的文件副本与文件服务器上的主副本相一致。"
          },
          {
            "三级标题": "10.7.3 命名及共享语义",
            "正文": "1.命名 如前面章节所述，对于OS管理的存储资源，文件系统通过抽象，屏蔽了对物理设备 的操作以及资源管理的细节，并向用户提供统一的、对象化的访问接口。在LFS中，用户 342  第十章多处理机操作系统 使用文件名访问逻辑数据对象，而逻辑数据对象所对应的是经过OS抽象过的系统底层， 即采用的是盘面、磁道号和扇区的方式对存储在本地磁盘上的物理对象(数据)进行访问。 但在DFS中，从逻辑对象到物理对象之间，还存在着磁盘所在的服务器地址问题。作为 DFS的抽象功能，不仅要将文件在磁盘的具体盘块、磁道和扇区等信息隐藏起来，将其与 文件名映射，完成一次文件的抽象，还需要隐藏文件所在服务器的地址和存储方式等细节， 将其也与文件名映射，从而形成一个多级映射，为用户提供的是一个文件的抽象。所谓命 名，就是在数据的逻辑对象和物理对象之间建立的映射。 在DFS中，主要有三种命名方案：\n\n（1）结合主机名和本地名对文件命名，保证在整个系统范围的唯一性。如，文件名为 “/host/local-name-path”，其中local-name 类似于UNIX的路径。该方案简单易行，但不符 合命名的透明性。\n\n(2）将若干台服务器中的远程目录，加载到客户机的本地目录中。该方案管理复杂度 很高，结构混乱，且安全程度低，一旦一个服务器故障，将导致客户机上的目录集失效。\n\n(3）全局统一命名，即系统采用统一的全局命名结构，每个文件和目录使用唯一的命 名。考虑到不同系统中的一些特殊文件，使得该方案实现难度较大。\n\n2.共享语义 对于DFS，需要保证多个客户机并发访问时的数据一致性，因此，当多个客户共享同 一个文件时，必须对客户机和服务器之间的交互协议精确处理，即精确定义读和写的语义。 例如，在服务器上有一个文件的主副本，客户机A因为频繁使用的原因，在自已本地 的高速缓存中也保留了该文件的一个副本。某一时刻，客户机A对本地高速缓存中的副本 进行了修改，然后，客户机B从服务器读取了这个文件。显然，客户机B得到的文件是一 个过时、失效的文件，可见这样读写语义存在问题。为了保持文件在客户机本地缓存中的 副本与服务器上的主副本的一致性，如果将上述语义改为：客户机A对本地高速缓存中文 件的任何修改，必须立即传回服务器。虽然表面上似乎解决了一致性问题，但实际上，因 没有界定修改的截止点，这种方式非常低效。另外一种方法是将语义改为：只有当客户机 A对文件修改完毕，执行关闭操作后，才将修改后的副本上传到服务器，并通知客户机B。 这样，客户机B进行后续的读操作，确保了B读到正确的文件。 由上述可知，共享语义决定了多个客户共享文件的效果，是评价DFS允许多个客户共 户看到。 通常，实现多个客户机共享文件的方法主要有四种：①UNIX语义，文件上的每个操 作对所有进程都是瞬间可见；②会话语义，在文件关闭之前，所有改动对其进程都是不可 见的；③不允许更新文件，不能进行更改，只能简单地进行共享和复制；④事务处理， 所有改动以原子操作的方式（顺序）发生。\n\n3.租赁协议 租赁协议是一个比较具有代表性的一致性访问协议。当客户机向服务器发出一个读请 求时，不仅收到所请求的数据，还会收到一个租赁凭据。该凭据附带一个有效期，保证服 务器在该有效期内不会对客户机收到的数据进行更新。 343  计算机操作系统 如果客户机数据在本地高速缓存上保留了副本，则在有效期内，客户机对数据的访问 只需在本地缓存中进行，不必重新请求服务器，数据也不用重新传送。只有当租赁的有效 期过期时，客户机才必须与服务器进行交互，确认本地缓存中的数据是否与服务器上的一 致，判断服务器上的数据是否进行了更新。只有确认发生了更新，客户机才必须重新向服 务器请求，以获得最新的数据。 作为服务器，当有客户机对数据发出更新请求时，并不是立即进行更新，而是向所有 持有对该文件租赁的客户机(即正在共享该文件的所有客户机)发出更新确认，然后才会实 施更新。所有客户机收到服务器发送的更新确认时，即将其持有的租赁凭据标记为无效。 此后，客户机需要再次访问该数据时，必须重新向服务器请求，在获得新数据的同时，获 取一张新的租赁凭证。 租赁协议实际上是一个多读者单写者的机制，即同一时间在同一文件上可以充许多个 客户机进行读操作，但对于客户机的写操作，同一时间只充许一个客户机进行，进行读写 操作的客户机只能互斥进行。"
          },
          {
            "三级标题": "10.7.4 远程文件访问和缓存 一 在DFS中，需要解决的一个很重要的问题是远程文件的访问方法。在C/S模式中，客 户使用远程服务机制访问文件，访问请求被送到服务器，服务器执行访问，并将结果回送 给客户。执行远程服务的最常用的方法是在第二章介绍的远程过程调用(RPC)。 考虑到客户一般会对数据有反复多次使用的情况，根据程序的局部性原理，在DFS中 引入了缓存机制，即如果客户请求的数据不在本地，则从服务器处取来数据的拷贝，送给 客户机。通常取来的数据量比实际请求的要多得多，例如整个文件或几个页面，所以随后 的访问，客户机可在本地副本中进行。",
            "正文": "1.缓存和远程服务的比较\n\n（1）使用缓存时，大量的远程访问可转为对本地的缓存访问，因此而获得的服务速度 与本地访问的一样快。\n\n（2）使用缓存时，服务器的负载和网络通信量都减少了，扩充能力加强了。而在使用 远程服务方法时，每次远程访问都是跨过网络处理的，明显增加了网络通信量和服务器负 载，引起性能下降。\n\n（3）缓存时，就网络总开销而言，与远程服务针对个别请求一系列应答的传输开销相 比，缓存采用以整个文件或文件的若干个页面这样的大批数据传输方式时，开销还是要低 很多。\n\n（4）缓存的主要缺点是一致性问题。在针对不经常写入的访问模式中，缓存方法是优 越的；但在频繁写的情况下，用于解决一致性问题的机制反而导致在性能、网络通信量和 服务器负载等方面的大量开销。\n\n(5）在用缓存作为远程访问方法的系统中，仿真集中式系统的共享语义是很困难的。 使用远程服务时，服务器将所有访问串行化，因此能够实现任何集中的共享语义。\n\n（6）机器间的接口不同，远程服务方式仅仅是本地文件系统接口在网络上的扩展，机 器间的接口就是本地客户机和文件系统之间的接口。而缓存方式中，数据是在服务器和客 344  第十章多处理机操作系统 户机之间整体传输，机器间的接口与上级的用户接口是不同的。\n\n2.缓存的粒度和位置 1)缓存的粒度 在DFS中，缓存的数据粒度（即数据单元)可以是文件的若干块，也可以是若干个文件， 乃至整个文件系统。缓存的数据粒度越大，存储的数据就越多，则客户机较多的访问可通 过缓存完成，一方面增加了访问速度，另一方面减少了通信的流量，降低了服务器的负载 等。但是，缓存的数据越多，一次性传输的开销增大，另一方面，在写频繁的情况下，花 费在保持数据一致性上的开销也增大。反之，粒度太小，降低了缓存的命中率，增加了通 信开销，加大了服务器负载，降低了客户机的访问速度。 同理，在缓存中，存储块的大小划分也会影响到缓存的性能。可见缓存的大小以及存 储块的大小都对缓存性能有较大的影响。 2）缓存的位置 在一个各自有主存和磁盘的客户-服务器系统中，有四个地方可以用来存储文件或存储 部分文件：服务器磁盘、服务器主存、客户机磁盘或者客户机主存。 存储所有文件最直接的位置是在服务器磁盘上，使用磁盘缓存最明显的优点就是可靠 性不会因为系统的故障而丢失。 利用主存作缓存器也有若干优点：首先，可支持无盘工作站：其次，速度快，从主存 缓存中访问数据比磁盘缓存快：第三，方便构造单缓存机制，服务器缓存器设在主存中， 如果客户缓存也使用主存，就可以构造一个单缓存机制，服务器和客户均可使用，协议简 单，易实现。两种缓存地点强调的功能不一样，主存缓存器主要减少访问时间，磁盘缓存 器主要提高可靠性和单个机器的自治性。\n\n3.缓存的更新 对于缓存中更新的数据块，选择什么时间和方式将其写回服务器，对系统的性能和可 靠性具有关键性的影响。目前存在下面几种写回策略：\n\n（1）直接写，一旦数据写到缓存器中，就把此数据写到服务器磁盘上，可靠性高。\n\n(2）延迟写，把修改先写到缓存中，等待一段时间再将其写到服务器磁盘上，但这样 可能语义不清。\n\n(3）驱逐时写，当被修改过的数据块将被从缓存中换出时，将数据块发送到服务器上。\n\n（4）周期性写，周期地扫描缓存，把从上次扫描以来已被修改过的块发送给服务器。\n\n（5）关闭时写，当文件关闭时把数据写回到服务器，与会话语义相对应。\n\n4.数据一致性 们是否一致后才能使用。如果不一致，则表明本地缓存的数据已经过时，那么这些数据就 不能为客户机提供数据访问服务，需要进行更新。对于这样的检查，有两个基本方法：\n\n(1）客户机发起：客户机与服务器联系，检查本地数据与服务器上的主副本是否一致。 这个方法的关键是这种有效性检查的频度范围可以从每次访问前都进行一次，到只对一个 文件的第一次访问（即打开文件)时进行，也可以按固定的时间间隔周期性进行。检查频率 的高低直接影响网络和服务器的负载。 345  计算机操作系统 器检测出可能不一致时，必须做出处理，如检测到一个文件在多个客户机竞争状态被打开 时，服务器使该缓存失效。该方法的问题在于违背客户/服务器工作模式。"
          },
          {
            "三级标题": "10.7.5 容错 一一←",
            "正文": "1.无状态服务和有状态服务 当客户机对远程文件进行访问时，有关被访问的文件、目录和客户机的信息等， 在服务器端是否需要进行跟踪、检查和保存等处理，存在着两种策略：\n\n(1）有状态服务（statefulfileservice)：指一个服务器对某个客户机提供数据服务时，缓 存了该客户机的有关信息，该服务器称为有状态服务器。\n\n(2）无状态服务(statelessfileservice)：指当服务器对某个客户机提供数据服务时，没有 缓存该客户机的有关信息，该服务器称为无状态服务器。\n\n2.容错性 上述两种策略对系统的容错性能有不同的影响，当服务器在一次数据服务过程中发生 崩溃时，两者之间的差别就尤其明显：前者将丢失所有易失性状态，需要有一种机制将其 重新恢复到崩溃前的状态；但是后者在系统崩溃后可方便地重新向客户机提供数据服务， 然而，也正是因为后者没有保留客户机的任何信息，所以需要更长的请求消息和更久的处 理过程。 有关DFS的容错性环境，定义了三种文件属性：\n\n（1）可恢复性，当对某个文件的操作失败，或由客户终断此操作时，如果文件能转换 到原来的一致性状态，则说明此文件是可恢复的； 此文件是坚定的；\n\n（3）可用性，如果无论何时一旦需要就可访问，甚至在某个机器和存储器崩溃，或者 在发生通信失效的情况下，某个文件仍然可被访问，则称这种文件是可用的。 一般而言，可恢复性可通过更新原子操作来保证，坚定性则可通过设备的余性来保 证，这方面的知识在本书第十二章系统安全中有较详细的阐述。\n\n3.可用性与文件复制 文件复制是保证可用性的一个余措施。这里的文件复制不是前面章节所讲的SFT三 级容错技术中的磁盘镜像（同一台机器不同介质上的文件复制），而是在DFS系统不同节点 的主机磁盘上的复制。 通过对每个文件在多个服务器上的独立备份，增加系统的可靠性，这样当一个文件服 务器出现问题时，仍允许通过其它文件服务器进行文件访问。另外，因为同一文件存在于 多个文件服务器上，因此，当多个客户机并行发出文件访问请求时，还可以把这些请求进 行分流，分发到这些服务器上，平衡了每个服务器的负载，避免了运行性能上的瓶颈。 文件复制机制设计过程中，对用户的透明性是必要的，一个文件多个副本的存在，在 进行文件访问服务过程中，由文件名映射到一个特定的副本是命名机制的任务，对高层应 该是不可见的。在底层，不同的副本必须用不同的标识符区分。但是对于用户而言，对文 346  第十章多处理机操作系统 件复制的控制又应该是可控的，即复制控制的一些功能应该设置在高层。 文件复制机制设计中另外一个重要问题就是文件副本的更新，从用户的观点而言，一 个文件的所有副本对应的都是同一个逻辑实体，所以，对于其中任何一个副本的更新，必 须引发所有副本的更新。可见，使用文件复制增加可用性的代价，就是要使用一个更为复 杂的更新协议，以及系统为保证一致性而需付出的大量开销。"
          }
        ]
      }
    ]
  }
]